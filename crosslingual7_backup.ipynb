{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Lambda\n",
    "\n",
    "# import by me\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, LSTM #, Merge\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from gensim import models\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "from keras.layers import merge\n",
    "\n",
    "from scipy.spatial.distance import cityblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "class ModelParam(object):\n",
    "    \"\"\"\n",
    "    define the parameters of the model\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size1, # sentence length of language1\n",
    "        input_size2, # sentence length of language2\n",
    "        vocab_size, \n",
    "        sent_size, \n",
    "        embedding_dim,\n",
    "        embedding_weights,\n",
    "        #sent_vector,\n",
    "    ):\n",
    "        self.input_size1 = input_size1\n",
    "        self.input_size2 = input_size2\n",
    "        self.vocab_size = vocab_size\n",
    "        self.sent_size = sent_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_weights = embedding_weights\n",
    "        #self.sent_vector = sent_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "# initialize some variables\n",
    "w2v_model = KeyedVectors.load_word2vec_format('vectors_embeddings.bin', binary=True)\n",
    "\n",
    "# Inpute size\n",
    "w2v_dim = 200\n",
    "\n",
    "n_units_1st_layer = 64\n",
    "\n",
    "# Training epoch number\n",
    "n_epoch = 100\n",
    "\n",
    "# Model Optimization parameters\n",
    "batch_size = 64\n",
    "gradient_clipping_norm = 1.25\n",
    "\n",
    "# File name (or the intact file path) which indicates the model you want to save.\n",
    "saved_model = \"embeddings_saved_model.hdf5\"\n",
    "\n",
    "# Whether use early stopping\n",
    "# If you turn off early stopping the auc values after each epoch will not be computed.\n",
    "early_stopping_or_not = True\n",
    "\n",
    "# Control parameters of early stopping\n",
    "min_delta_value = 1e-3\n",
    "patience_steps_num =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "# TRAIN_CSV = 'train1.csv'\n",
    "TRAIN_CSV = 'train_original.csv'\n",
    "TEST_CSV = 'test.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "def text_to_word_list(text):\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.upper()\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words found in model = \n",
      "1745024\n",
      "words NOT found in model\n",
      "0\n",
      "vocab size  43254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:58: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the loaded embeddings\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 7.02004805e-02 -9.54385817e-01  4.67588007e-01 ...  2.22066343e-01\n",
      "   6.05751812e-01 -8.38298917e-01]\n",
      " [-6.98797181e-02 -1.16516185e+00  2.76971191e-01 ...  6.78086698e-01\n",
      "   4.69638079e-01 -5.87370574e-01]\n",
      " ...\n",
      " [-2.02880870e-03 -2.38929759e-03 -2.26852414e-03 ... -1.52107235e-03\n",
      "  -1.53823849e-03  8.48464959e-04]\n",
      " [ 3.94527204e-02 -5.25413267e-02  2.50864401e-02 ... -1.61156747e-02\n",
      "   1.87546294e-02 -1.14719808e-01]\n",
      " [ 1.00708006e-04  6.65512111e-04 -2.10678112e-03 ...  7.23190315e-04\n",
      "   2.73895275e-04  1.80854800e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "\n",
    "#test counters\n",
    "wordFound = 0\n",
    "wordNotFound = 0\n",
    "# Prepare embedding\n",
    "vocabulary = dict()\n",
    " # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
    "inverse_vocabulary = ['<unk>'] \n",
    "\n",
    "questions_cols = ['lang1', 'lang2']\n",
    "\n",
    "# Iterate over the questions only of both training and test datasets\n",
    "#For now Test dataset is a dummy small dataset with some instructions from training dataset\n",
    "dataset = train_df\n",
    "for index, row in dataset.iterrows():\n",
    "\n",
    "    # Iterate through the text of both questions of the row\n",
    "    for question in questions_cols:\n",
    "\n",
    "        q2n = []  # q2n -> question numbers representation\n",
    "        for word in text_to_word_list(row[question]):\n",
    "            #print(word)\n",
    "            # Check for unwanted words\n",
    "            if word not in w2v_model.wv:\n",
    "                print(\"Unknown word is found!!!\")\n",
    "                wordNotFound += 1\n",
    "                continue\n",
    "\n",
    "\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = len(inverse_vocabulary)\n",
    "                q2n.append(len(inverse_vocabulary))\n",
    "                inverse_vocabulary.append(word)\n",
    "            else:\n",
    "                q2n.append(vocabulary[word])\n",
    "\n",
    "            wordFound += 1\n",
    "        # Replace questions as word to question as number representation\n",
    "        dataset.at[index, question] = q2n\n",
    "            \n",
    "embedding_dim = w2v_dim\n",
    "# This will be the embedding matrix\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  \n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "#print test counters\n",
    "print(\"words found in model = \")\n",
    "print(wordFound)\n",
    "print(\"words NOT found in model\")\n",
    "print(wordNotFound)\n",
    "\n",
    "VOCAB_SIZE = len(vocabulary)\n",
    "print('vocab size ',VOCAB_SIZE)\n",
    "# Building the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    #print('index ', index)\n",
    "    if word in w2v_model.wv:\n",
    "        #print(word)\n",
    "        #print(\"above word found\")\n",
    "        embeddings[index] = w2v_model.wv[word]\n",
    "        \n",
    "print(\"This is the loaded embeddings\")\n",
    "\n",
    "print(embeddings)\n",
    "\n",
    "# MOVQ~RBX,[RSP+0] LDR~R0,[R10+0]\n",
    "# values = vocabulary.values()\n",
    "# idx = values.index(\"MOVQ~RBX,[RSP+0]\")\n",
    "# print('idx = ',idx)\n",
    "# vocabulary.get('LDR~R0,[R10+0]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "# This is the model for generating predictions\n",
    "# Takes parameters from ModelParam class\n",
    "\n",
    "class crossLingualModel(nn.Module):\n",
    "    def __init__(self, model_param: ModelParam):\n",
    "        super().__init__()\n",
    "        #Ifty\n",
    "#         self.embedding = nn.Embedding(\n",
    "#             model_param.vocab_size,\n",
    "#             model_param.embedding_dim\n",
    "#         )\n",
    "        #self.embedding = embeddings\n",
    "        #self.sent_vector = model_param.sent_vector\n",
    "        \n",
    "        # NEED TO CHECK PARAMETERS\n",
    "        # Keras embedding\n",
    "#         self.embedding = Embedding(model_param.vocab_size,\n",
    "#                             model_param.embedding_dim,\n",
    "#                             weights=[embeddings],\n",
    "#                             #input_length=MAX_SEQUENCE_LENGTH,\n",
    "#                             trainable=True)\n",
    "        # torch embedding\n",
    "        ## No CHANGE in embedding for both random and pre trained vectors\n",
    "        self.embedding = nn.Embedding(model_param.vocab_size,\n",
    "                            model_param.embedding_dim)\n",
    "#         weight = torch.FloatTensor(model_param.embedding_weights)\n",
    "#         self.embedding = nn.Embedding.from_pretrained(weight, freeze=False)\n",
    "\n",
    "#         self.embedding.weight.data.copy_(torch.from_numpy(model_param.embedding_weights))\n",
    "        self.embedding.weight.data.copy_(model_param.embedding_weights)\n",
    "    \n",
    "        self.embedding.weight.requires_grad = True # for updating weights\n",
    "        \n",
    "        self.sent = torch.randn(\n",
    "            model_param.sent_size, \n",
    "            requires_grad=True, \n",
    "            dtype=torch.float\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(\n",
    "            model_param.embedding_dim + model_param.sent_size,\n",
    "            model_param.vocab_size\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # x1: embeddings of context words in lang1\n",
    "    # x2: embeddings of context words in lang2\n",
    "    def forward(self, x1, x2, sent_vector):\n",
    "        if(len(sent_vector) == 0 ):\n",
    "            #Do Testing part\n",
    "            #Now x1 and x2 are instructions in lang1 and lang2\n",
    "            \n",
    "            sent_vector_lang1 = text_to_word_list(x1)\n",
    "            sent_vector_lang1 = [word for word in sent_vector_lang1 if word in w2v_model.wv]\n",
    "            sent_vector_lang1_index_array = []\n",
    "            for word in sent_vector_lang1:\n",
    "                sent_vector_lang1_index_array.append(vocabulary.get(word))\n",
    "            sent_vector_lang1 = np.array(sent_vector_lang1_index_array)\n",
    "            \n",
    "            sent_vector_lang1 = torch.Tensor(sent_vector_lang1)\n",
    "#             print('sent_vector_lang1 5', sent_vector_lang1)\n",
    "            sent_vector_lang1 = sent_vector_lang1.to(torch.int)\n",
    "#             print('sent_vector_lang1 6', sent_vector_lang1)\n",
    "            \n",
    "            sent_vector_lang1 = self.embedding(sent_vector_lang1)\n",
    "            #print('embedding_output1 ',embedding_output1)\n",
    "#             sent_vector_lang1 = sent_vector_lang1.numpy()\n",
    "            if len(sent_vector_lang1) >= 1:\n",
    "                sent_vector_lang1 = torch.Tensor([x.sum()/len(x) for x in sent_vector_lang1.transpose(0, -1)]) # .transpose(0, -1)\n",
    "                \n",
    "#                 sent_vector_lang1 = np.mean(sent_vector_lang1, axis=0)\n",
    "            else:\n",
    "                sent_vector_lang1 = torch.zeros(w2v_dim)\n",
    "                \n",
    "            sent_vector_lang2 = text_to_word_list(x2)\n",
    "            sent_vector_lang2 = [word for word in sent_vector_lang2 if word in w2v_model.wv]\n",
    "            sent_vector_lang2_index_array = []\n",
    "            for word in sent_vector_lang2:\n",
    "                sent_vector_lang2_index_array.append(vocabulary.get(word))\n",
    "            sent_vector_lang2 = np.array(sent_vector_lang2_index_array)\n",
    "            \n",
    "            sent_vector_lang2 = torch.Tensor(sent_vector_lang2)\n",
    "#             print('sent_vector_lang2 5', sent_vector_lang2)\n",
    "            sent_vector_lang2 = sent_vector_lang2.to(torch.int)\n",
    "#             print('sent_vector_lang2 6', sent_vector_lang2)\n",
    "            \n",
    "            sent_vector_lang2 = self.embedding(sent_vector_lang2)\n",
    "#             print('embedding_output sent_vector_lang2 ',sent_vector_lang2)\n",
    "#             sent_vector_lang2 = sent_vector_lang2.numpy()\n",
    "            if len(sent_vector_lang2) >= 1:\n",
    "                sent_vector_lang2 = torch.Tensor([x.sum()/len(x) for x in sent_vector_lang2.transpose(0, -1)]) # .transpose(0, -1)\n",
    "                \n",
    "#                 sent_vector_lang2 = np.mean(sent_vector_lang2, axis=0)\n",
    "            else:\n",
    "                sent_vector_lang2 = torch.zeros(w2v_dim)\n",
    "            \n",
    "            #Not sure if these two lines should be added\n",
    "#             print('sent_vector_lang1 size ', sent_vector_lang1.size())\n",
    "#             sent_vector_lang1 = self.linear(sent_vector_lang1)\n",
    "#             sent_vector_lang2 = self.linear(sent_vector_lang2)\n",
    "            \n",
    "            return [sent_vector_lang1, sent_vector_lang2]\n",
    "        else:\n",
    "            #Do prediction part\n",
    "            #x1 = torch.FloatTensor(x1)\n",
    "            #x2= torch.FloatTensor(x2)\n",
    "\n",
    "            #modify part\n",
    "            #NEED to get indices from words list in x1 and x2\n",
    "            x1_index_array = []\n",
    "            for word in x1:\n",
    "                x1_index_array.append(vocabulary.get(word))\n",
    "\n",
    "            x2_index_array = []\n",
    "            for word in x2:\n",
    "                x2_index_array.append(vocabulary.get(word))\n",
    "\n",
    "\n",
    "#             x1 = np.array(x1_index_array) #, dtype=np.int32)\n",
    "#             x2 = np.array(x2_index_array) #, dtype=np.int32)\n",
    "\n",
    "            x1 = x1_index_array #, dtype=np.int32)\n",
    "            x2 = x2_index_array #, dtype=np.int32)\n",
    "            \n",
    "            x1 = torch.Tensor(x1)\n",
    "            x2 = torch.Tensor(x2)\n",
    "            x1 = x1.to(torch.int)\n",
    "            x2 = x2.to(torch.int)\n",
    "            \n",
    "            \n",
    "    #         x1 = np.array((x1))\n",
    "    #         x2 = np.array((x2))\n",
    "            embedding_output1 = self.embedding(x1)\n",
    "#             tmp = 3\n",
    "#             if tmp in x1:\n",
    "#             embeddings_layer_weights = self.embedding.get_weights()[0]\n",
    "#             print('embeddings_layer_weights ',embeddings_layer_weights)\n",
    "\n",
    "#             print('for x1 = ', x1)\n",
    "#             print('embedding_output1',embedding_output1)\n",
    "                \n",
    "            # Write embedding o/p to file\n",
    "            f = open(\"output_of_small_train_set_after_ten_epoch.txt\", \"a\")\n",
    "            f.write(str(x1))\n",
    "            f.write(str(embedding_output1))\n",
    "            f.close()\n",
    "        \n",
    "#             current_vec = self.embedding.weight\n",
    "#             if prev_vec != current_vec:\n",
    "#                 print('!=')\n",
    "#             else:\n",
    "#                 print('==')\n",
    "#             prev_vec = current_vec\n",
    "            \n",
    "#             print(\"embedding weight \",self.embedding.weight)\n",
    "\n",
    "#             embedding_output1 = torch.Tensor(embedding_output1.numpy())\n",
    "\n",
    "    #         embedding_output1 = torch.FloatTensor(embedding_output1) #torch.Tensor(embedding_output1)\n",
    "            embedding_output1 = F.relu(embedding_output1)\n",
    "        \n",
    "#             f = open(\"output_of_small_train_set_after_ten_epoch.txt\", \"a\")\n",
    "#             f.write(str(x1))\n",
    "#             f.write(str(embedding_output1))\n",
    "#             f.close()\n",
    "#             print('embedding_output1 relu size = ',embedding_output1.size())\n",
    "#             print('embedding_output1 relu = ',embedding_output1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            embedding_output2 = self.embedding(x2)\n",
    "#             embedding_output2 = torch.Tensor(embedding_output2.numpy())\n",
    "            embedding_output2 = F.relu(embedding_output2)\n",
    "\n",
    "            #working part\n",
    "    #         embedding_output1 = x1 \n",
    "    #         embedding_output1 = F.relu(embedding_output1)\n",
    "    #         embedding_output2 = x2 \n",
    "    #         embedding_output2 = F.relu(embedding_output2)\n",
    "\n",
    "\n",
    "\n",
    "            sum_embedding1 = torch.Tensor([x.sum() for x in embedding_output1.transpose(0, -1)])\n",
    "            sum_embedding2 = torch.Tensor([x.sum() for x in embedding_output2.transpose(0, -1)])\n",
    "            sent = self.sent\n",
    "\n",
    "            # For modifying sent vector using embedding layer\n",
    "#             print('sent_vector 1', sent_vector)\n",
    "            sent_vector = text_to_word_list(sent_vector)\n",
    "#             print('sent_vector 2', sent_vector)\n",
    "            sent_vector = [word for word in sent_vector if word in w2v_model.wv]\n",
    "#             print('sent_vector 3', sent_vector)\n",
    "        \n",
    "            sent_vector_index_array = []\n",
    "            for word in sent_vector:\n",
    "                sent_vector_index_array.append(vocabulary.get(word))\n",
    "#             sent_vector = np.array(sent_vector_index_array)\n",
    "            sent_vector = sent_vector_index_array\n",
    "#             print('sent_vector 4', sent_vector)\n",
    "            \n",
    "            \n",
    "            sent_vector = torch.Tensor(sent_vector)\n",
    "#             print('sent_vector 5', sent_vector)\n",
    "            \n",
    "            sent_vector = sent_vector.to(torch.int)\n",
    "#             print('sent_vector 6', sent_vector)\n",
    "            \n",
    "            \n",
    "            sent_vector = self.embedding(sent_vector)\n",
    "#             print('sent_vector 7', sent_vector)\n",
    "            \n",
    "            #print('embedding_output1 ',embedding_output1)\n",
    "#             sent_vector = sent_vector.numpy()\n",
    "#             if len(sent_vector) >= 1:\n",
    "#             if tf.equal(tf.size(sent_vector), 0):\n",
    "#                  sent_vector = torch.mean(sent_vector)\n",
    "#             else:\n",
    "#                 sent_vector = torch.zeros(w2v_dim)\n",
    "\n",
    "#             sent_vector = torch.split(sent_vector, 1)\n",
    "#             sent_vector = torch.mean(torch.stack(sent_vector))\n",
    "\n",
    "#             mean = torch.mean(torch.stack(my_list))\n",
    "#             sent_vector = torch.mean(sent_vector)\n",
    "\n",
    "            # may need to change later\n",
    "#             sent_vector = sent_vector.detach().numpy()\n",
    "#             sent_vector = np.mean(sent_vector)\n",
    "        \n",
    "            # NEED TO FIND A WAY TO GET ELEMENT WISE AVERAGE OF TENSORS\n",
    "            sent_vector = torch.Tensor([x.sum()/len(x) for x in sent_vector.transpose(0, -1)]) # .transpose(0, -1)\n",
    "        \n",
    "#             print('sent_vector 8', sent_vector)\n",
    "    \n",
    "#             print('sent_vector.size ',sent_vector.size())\n",
    "#             print('sum_embedding1.size ',sum_embedding1.size())\n",
    "            \n",
    "\n",
    "            concat1 = torch.cat((sum_embedding1, torch.Tensor(sent_vector)), 0)\n",
    "            concat2 = torch.cat((sum_embedding2, torch.Tensor(sent_vector)), 0)\n",
    "\n",
    "\n",
    "    #         concat1 = torch.cat((sum_embedding1, torch.Tensor(sent_vector)), 0)\n",
    "    #         concat2 = torch.cat((sum_embedding2, torch.Tensor(sent_vector)), 0)\n",
    "    \n",
    "#             print('concat1 size ', concat1.size())\n",
    "\n",
    "            linear_output1 = self.linear(concat1)\n",
    "            linear_output2 = self.linear(concat2)\n",
    "            \n",
    "            print(self.linear.weight)\n",
    "\n",
    "\n",
    "\n",
    "#             pred1 = self.softmax(linear_output1.reshape(1,-1))\n",
    "#             pred2 = self.softmax(linear_output2.reshape(1,-1))\n",
    "            \n",
    "            \n",
    "#             pred1 = self.sigmoid(linear_output1.reshape(1,-1))\n",
    "#             pred2 = self.sigmoid(linear_output2.reshape(1,-1))\n",
    "            \n",
    "#             pred1 = pred1.narrow(1,0,200)\n",
    "#             pred2 = pred2.narrow(1,0,200)\n",
    "            \n",
    "\n",
    "            # May need to sort\n",
    "    #         print('pred1 size ', pred1.size())\n",
    "    #         pred1 = torch.cat([pred1[0:200]]) #pred1[:200] #torch.reshape(pred1, (200, -1))\n",
    "    #         pred2 = torch.cat([pred2[0:200]]) #pred2[:200] #torch.reshape(pred2, (200, -1))\n",
    "#             print('after narrow pred1 size ', pred1.size())\n",
    "\n",
    "            return [self.softmax(linear_output1.reshape(1,-1)).narrow(1,0,200), self.softmax(linear_output2.reshape(1,-1)).narrow(1,0,200)]\n",
    "#             return [self.softmax(linear_output1.reshape(1,-1)), self.softmax(linear_output2.reshape(1,-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "# TRY WITH OUT REWRAPPING\n",
    "# This is the model for generating predictions\n",
    "# Takes parameters from ModelParam class\n",
    "\n",
    "class crossLingualModel(nn.Module):\n",
    "    def __init__(self, model_param: ModelParam):\n",
    "        super().__init__()\n",
    "        #Ifty\n",
    "#         self.embedding = nn.Embedding(\n",
    "#             model_param.vocab_size,\n",
    "#             model_param.embedding_dim\n",
    "#         )\n",
    "        #self.embedding = embeddings\n",
    "        #self.sent_vector = model_param.sent_vector\n",
    "        \n",
    "        # NEED TO CHECK PARAMETERS\n",
    "        # Keras embedding\n",
    "#         self.embedding = Embedding(model_param.vocab_size,\n",
    "#                             model_param.embedding_dim,\n",
    "#                             weights=[embeddings],\n",
    "#                             #input_length=MAX_SEQUENCE_LENGTH,\n",
    "#                             trainable=True)\n",
    "        # torch embedding\n",
    "        ## No CHANGE in embedding for both random and pre trained vectors\n",
    "        self.embedding = nn.Embedding(model_param.vocab_size,\n",
    "                            model_param.embedding_dim)\n",
    "#         weight = torch.FloatTensor(model_param.embedding_weights)\n",
    "#         self.embedding = nn.Embedding.from_pretrained(weight, freeze=False)\n",
    "\n",
    "#         self.embedding.weight.data.copy_(torch.from_numpy(model_param.embedding_weights))\n",
    "        self.embedding.weight.data.copy_(model_param.embedding_weights)\n",
    "    \n",
    "        self.embedding.weight.requires_grad = True # for updating weights\n",
    "        \n",
    "        self.sent = torch.randn(\n",
    "            model_param.sent_size, \n",
    "            requires_grad=True, \n",
    "            dtype=torch.float\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Linear(\n",
    "            model_param.embedding_dim + model_param.sent_size,\n",
    "            model_param.vocab_size\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # x1: embeddings of context words in lang1\n",
    "    # x2: embeddings of context words in lang2\n",
    "    def forward(self, x1, x2, sent_vector):\n",
    "        if(len(sent_vector) == 0 ):\n",
    "            #Do Testing part\n",
    "            #Now x1 and x2 are instructions in lang1 and lang2\n",
    "            \n",
    "            sent_vector_lang1 = text_to_word_list(x1)\n",
    "            sent_vector_lang1 = [word for word in sent_vector_lang1 if word in w2v_model.wv]\n",
    "            sent_vector_lang1_index_array = []\n",
    "            for word in sent_vector_lang1:\n",
    "                sent_vector_lang1_index_array.append(vocabulary.get(word))\n",
    "#             sent_vector_lang1 = np.array(sent_vector_lang1_index_array)\n",
    "            sent_vector_lang1 = sent_vector_lang1_index_array\n",
    "            \n",
    "            \n",
    "            sent_vector_lang1 = torch.Tensor(sent_vector_lang1)\n",
    "#             print('sent_vector_lang1 5', sent_vector_lang1)\n",
    "            sent_vector_lang1 = sent_vector_lang1.to(torch.int)\n",
    "#             print('sent_vector_lang1 6', sent_vector_lang1)\n",
    "            \n",
    "            sent_vector_lang1 = self.embedding(sent_vector_lang1)\n",
    "            #print('embedding_output1 ',embedding_output1)\n",
    "#             sent_vector_lang1 = sent_vector_lang1.numpy()\n",
    "            if len(sent_vector_lang1) >= 1:\n",
    "                sent_vector_lang1 = torch.stack([x.sum()/len(x) for x in sent_vector_lang1.transpose(0, -1)]) # .transpose(0, -1)\n",
    "                \n",
    "#                 sent_vector_lang1 = np.mean(sent_vector_lang1, axis=0)\n",
    "            else:\n",
    "                sent_vector_lang1 = torch.zeros(w2v_dim)\n",
    "                \n",
    "            sent_vector_lang2 = text_to_word_list(x2)\n",
    "            sent_vector_lang2 = [word for word in sent_vector_lang2 if word in w2v_model.wv]\n",
    "            sent_vector_lang2_index_array = []\n",
    "            for word in sent_vector_lang2:\n",
    "                sent_vector_lang2_index_array.append(vocabulary.get(word))\n",
    "#             sent_vector_lang2 = np.array(sent_vector_lang2_index_array)\n",
    "            sent_vector_lang2 = sent_vector_lang2_index_array\n",
    "            \n",
    "            \n",
    "            sent_vector_lang2 = torch.Tensor(sent_vector_lang2)\n",
    "#             print('sent_vector_lang2 5', sent_vector_lang2)\n",
    "            sent_vector_lang2 = sent_vector_lang2.to(torch.int)\n",
    "#             print('sent_vector_lang2 6', sent_vector_lang2)\n",
    "            \n",
    "            sent_vector_lang2 = self.embedding(sent_vector_lang2)\n",
    "#             print('embedding_output sent_vector_lang2 ',sent_vector_lang2)\n",
    "#             sent_vector_lang2 = sent_vector_lang2.numpy()\n",
    "            if len(sent_vector_lang2) >= 1:\n",
    "                sent_vector_lang2 = torch.stack([x.sum()/len(x) for x in sent_vector_lang2.transpose(0, -1)]) # .transpose(0, -1)\n",
    "                \n",
    "#                 sent_vector_lang2 = np.mean(sent_vector_lang2, axis=0)\n",
    "            else:\n",
    "                sent_vector_lang2 = torch.zeros(w2v_dim)\n",
    "            \n",
    "            #Not sure if these two lines should be added\n",
    "#             print('sent_vector_lang1 size ', sent_vector_lang1.size())\n",
    "#             sent_vector_lang1 = self.linear(sent_vector_lang1)\n",
    "#             sent_vector_lang2 = self.linear(sent_vector_lang2)\n",
    "            \n",
    "            return [sent_vector_lang1, sent_vector_lang2]\n",
    "        else:\n",
    "            #Do prediction part\n",
    "            #x1 = torch.FloatTensor(x1)\n",
    "            #x2= torch.FloatTensor(x2)\n",
    "\n",
    "            #modify part\n",
    "            #NEED to get indices from words list in x1 and x2\n",
    "            x1_index_array = []\n",
    "            for word in x1:\n",
    "                x1_index_array.append(vocabulary.get(word))\n",
    "\n",
    "            x2_index_array = []\n",
    "            for word in x2:\n",
    "                x2_index_array.append(vocabulary.get(word))\n",
    "\n",
    "\n",
    "#             x1 = np.array(x1_index_array) #, dtype=np.int32)\n",
    "#             x2 = np.array(x2_index_array) #, dtype=np.int32)\n",
    "\n",
    "            x1 = x1_index_array #, dtype=np.int32)\n",
    "            x2 = x2_index_array #, dtype=np.int32)\n",
    "            \n",
    "            x1 = torch.Tensor(x1)\n",
    "            x2 = torch.Tensor(x2)\n",
    "            x1 = x1.to(torch.int)\n",
    "            x2 = x2.to(torch.int)\n",
    "            \n",
    "            \n",
    "    #         x1 = np.array((x1))\n",
    "    #         x2 = np.array((x2))\n",
    "            embedding_output1 = self.embedding(x1)\n",
    "#             tmp = 3\n",
    "#             if tmp in x1:\n",
    "#             embeddings_layer_weights = self.embedding.get_weights()[0]\n",
    "#             print('embeddings_layer_weights ',embeddings_layer_weights)\n",
    "\n",
    "#             print('for x1 = ', x1)\n",
    "#             print('embedding_output1',embedding_output1)\n",
    "                \n",
    "            # Write embedding o/p to file\n",
    "            f = open(\"output_of_small_train_set_after_ten_epoch.txt\", \"a\")\n",
    "            f.write(str(x1))\n",
    "            f.write(str(embedding_output1))\n",
    "            f.close()\n",
    "        \n",
    "#             current_vec = self.embedding.weight\n",
    "#             if prev_vec != current_vec:\n",
    "#                 print('!=')\n",
    "#             else:\n",
    "#                 print('==')\n",
    "#             prev_vec = current_vec\n",
    "            \n",
    "#             print(\"embedding weight \",self.embedding.weight)\n",
    "\n",
    "#             embedding_output1 = torch.Tensor(embedding_output1.numpy())\n",
    "\n",
    "    #         embedding_output1 = torch.FloatTensor(embedding_output1) #torch.Tensor(embedding_output1)\n",
    "            embedding_output1 = F.relu(embedding_output1)\n",
    "        \n",
    "#             f = open(\"output_of_small_train_set_after_ten_epoch.txt\", \"a\")\n",
    "#             f.write(str(x1))\n",
    "#             f.write(str(embedding_output1))\n",
    "#             f.close()\n",
    "#             print('embedding_output1 relu size = ',embedding_output1.size())\n",
    "#             print('embedding_output1 relu = ',embedding_output1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            embedding_output2 = self.embedding(x2)\n",
    "#             embedding_output2 = torch.Tensor(embedding_output2.numpy())\n",
    "            embedding_output2 = F.relu(embedding_output2)\n",
    "\n",
    "            #working part\n",
    "    #         embedding_output1 = x1 \n",
    "    #         embedding_output1 = F.relu(embedding_output1)\n",
    "    #         embedding_output2 = x2 \n",
    "    #         embedding_output2 = F.relu(embedding_output2)\n",
    "\n",
    "\n",
    "\n",
    "#             sum_embedding1 = torch.Tensor([x.sum() for x in embedding_output1.transpose(0, -1)])\n",
    "#             sum_embedding2 = torch.Tensor([x.sum() for x in embedding_output2.transpose(0, -1)])\n",
    "            \n",
    "            sum_embedding1 = torch.stack([x.sum() for x in embedding_output1.transpose(0, -1)])\n",
    "            sum_embedding2 = torch.stack([x.sum() for x in embedding_output2.transpose(0, -1)])\n",
    "#             print('sum_embedding1 ',sum_embedding1)\n",
    "            sent = self.sent\n",
    "\n",
    "            # For modifying sent vector using embedding layer\n",
    "#             print('sent_vector 1', sent_vector)\n",
    "            sent_vector = text_to_word_list(sent_vector)\n",
    "#             print('sent_vector 2', sent_vector)\n",
    "            sent_vector = [word for word in sent_vector if word in w2v_model.wv]\n",
    "#             print('sent_vector 3', sent_vector)\n",
    "        \n",
    "            sent_vector_index_array = []\n",
    "            for word in sent_vector:\n",
    "                sent_vector_index_array.append(vocabulary.get(word))\n",
    "#             sent_vector = np.array(sent_vector_index_array)\n",
    "            sent_vector = sent_vector_index_array\n",
    "#             print('sent_vector 4', sent_vector)\n",
    "            \n",
    "            \n",
    "            sent_vector = torch.Tensor(sent_vector)\n",
    "#             print('sent_vector 5', sent_vector)\n",
    "            \n",
    "            sent_vector = sent_vector.to(torch.int)\n",
    "#             print('sent_vector 6', sent_vector)\n",
    "            \n",
    "            \n",
    "            sent_vector = self.embedding(sent_vector)\n",
    "#             print('sent_vector 7', sent_vector)\n",
    "            \n",
    "            #print('embedding_output1 ',embedding_output1)\n",
    "#             sent_vector = sent_vector.numpy()\n",
    "#             if len(sent_vector) >= 1:\n",
    "#             if tf.equal(tf.size(sent_vector), 0):\n",
    "#                  sent_vector = torch.mean(sent_vector)\n",
    "#             else:\n",
    "#                 sent_vector = torch.zeros(w2v_dim)\n",
    "\n",
    "#             sent_vector = torch.split(sent_vector, 1)\n",
    "#             sent_vector = torch.mean(torch.stack(sent_vector))\n",
    "\n",
    "#             mean = torch.mean(torch.stack(my_list))\n",
    "#             sent_vector = torch.mean(sent_vector)\n",
    "\n",
    "            # may need to change later\n",
    "#             sent_vector = sent_vector.detach().numpy()\n",
    "#             sent_vector = np.mean(sent_vector)\n",
    "        \n",
    "            # NEED TO FIND A WAY TO GET ELEMENT WISE AVERAGE OF TENSORS\n",
    "#             sent_vector = torch.Tensor([x.sum()/len(x) for x in sent_vector.transpose(0, -1)]) # .transpose(0, -1)\n",
    "            sent_vector = torch.stack([x.sum()/len(x) for x in sent_vector.transpose(0, -1)]) # .transpose(0, -1)\n",
    "#             print('sent_vector ', sent_vector)\n",
    "#             print('sent_vector 8', sent_vector)\n",
    "    \n",
    "#             print('sent_vector.size ',sent_vector.size())\n",
    "#             print('sum_embedding1.size ',sum_embedding1.size())\n",
    "            \n",
    "\n",
    "#             concat1 = torch.cat((sum_embedding1, torch.Tensor(sent_vector)), 0)\n",
    "#             concat2 = torch.cat((sum_embedding2, torch.Tensor(sent_vector)), 0)\n",
    "            \n",
    "            concat1 = torch.cat((sum_embedding1, sent_vector), 0)\n",
    "            concat2 = torch.cat((sum_embedding2, sent_vector), 0)\n",
    "\n",
    "\n",
    "    #         concat1 = torch.cat((sum_embedding1, torch.Tensor(sent_vector)), 0)\n",
    "    #         concat2 = torch.cat((sum_embedding2, torch.Tensor(sent_vector)), 0)\n",
    "    \n",
    "#             print('concat1 size ', concat1.size())\n",
    "\n",
    "            linear_output1 = self.linear(concat1)\n",
    "            linear_output2 = self.linear(concat2)\n",
    "            \n",
    "#             print(self.linear.weight)\n",
    "\n",
    "\n",
    "\n",
    "#             pred1 = self.softmax(linear_output1.reshape(1,-1))\n",
    "#             pred2 = self.softmax(linear_output2.reshape(1,-1))\n",
    "            \n",
    "            \n",
    "#             pred1 = self.sigmoid(linear_output1.reshape(1,-1))\n",
    "#             pred2 = self.sigmoid(linear_output2.reshape(1,-1))\n",
    "            \n",
    "#             pred1 = pred1.narrow(1,0,200)\n",
    "#             pred2 = pred2.narrow(1,0,200)\n",
    "            \n",
    "\n",
    "            # May need to sort\n",
    "    #         print('pred1 size ', pred1.size())\n",
    "    #         pred1 = torch.cat([pred1[0:200]]) #pred1[:200] #torch.reshape(pred1, (200, -1))\n",
    "    #         pred2 = torch.cat([pred2[0:200]]) #pred2[:200] #torch.reshape(pred2, (200, -1))\n",
    "#             print('after narrow pred1 size ', pred1.size())\n",
    "\n",
    "            return [self.softmax(linear_output1.reshape(1,-1)).narrow(1,0,200), self.softmax(linear_output2.reshape(1,-1)).narrow(1,0,200)]\n",
    "#             return [self.softmax(linear_output1.reshape(1,-1)), self.softmax(linear_output2.reshape(1,-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "# For calculating word vector\n",
    "def get_mean_vector(words):\n",
    "    # remove out-of-vocabulary words #w2v_model.wv\n",
    "    words = [word for word in words if word in w2v_model.wv]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(w2v_model.wv[words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2v_dim) #[]\n",
    "\n",
    "# Run this cell\n",
    "# For getting center word and surrounding words according to sliding window with window size C\n",
    "def get_windows(words_lang1, words_lang2, C):\n",
    "    i = C\n",
    "    #get word_list with min length\n",
    "    lang1_len = len(words_lang1)\n",
    "    lang2_len = len(words_lang2)\n",
    "    min_len = min(lang1_len, lang2_len)\n",
    "    \n",
    "    while i < min_len - C:\n",
    "        center_word_lang1 = words_lang1[i]\n",
    "        center_word_lang2 = words_lang2[i]\n",
    "        context_words_lang1 = words_lang1[(i - C):i] + words_lang1[(i+1):(i+C+1)]\n",
    "        context_words_lang2 = words_lang2[(i - C):i] + words_lang2[(i+1):(i+C+1)]\n",
    "        yield context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 \n",
    "        i += 1\n",
    "        \n",
    "# Run this cell\n",
    "def get_normalized_tensor(input_array):\n",
    "    min_v = torch.min(input_array)\n",
    "    range_v = torch.max(input_array) - min_v\n",
    "    if range_v > 0:\n",
    "        normalised = (input_array - min_v) / range_v\n",
    "    else:\n",
    "        normalised = torch.zeros(input_array.size())\n",
    "    input_array = normalised\n",
    "    return input_array\n",
    "\n",
    "def get_normalized_array_from_array_using_tensor_formula(input_array):\n",
    "    input_array = torch.from_numpy(input_array)\n",
    "    input_array = torch.autograd.Variable(input_array)\n",
    "    input_array = input_array.reshape(1,-1)\n",
    "    \n",
    "    return get_normalized_tensor(input_array).detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from numpy import asarray\n",
    "# from keras import backend\n",
    "# from keras.losses import binary_crossentropy\n",
    "# # For calculating binary_crossentropy using keras\n",
    "# def get_cross_entropy(target, predicted):\n",
    "#     # prepare classification data\n",
    "#     #p = asarray([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "#     #q = asarray([0.8, 0.9, 0.9, 0.6, 0.8, 0.1, 0.4, 0.2, 0.1, 0.3])\n",
    "#     # convert to keras variables\n",
    "    \n",
    "#     y_true = backend.variable(target)\n",
    "#     y_pred = backend.variable(predicted)\n",
    "#     # calculate the average cross-entropy\n",
    "#     mean_ce = backend.eval(binary_crossentropy(y_true, y_pred))\n",
    "#     #print('Average Cross Entropy: %.3f nats' % mean_ce)\n",
    "#     return mean_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2018 Stefano Nardo https://gist.github.com/stefanonardo\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        print('metrics ',metrics)\n",
    "        if self.best is None:\n",
    "            print('is None')\n",
    "            self.best = metrics\n",
    "            print('self.best = ',self.best)\n",
    "            return False\n",
    "\n",
    "#         if torch.isnan(metrics):\n",
    "#             print('isnan')\n",
    "#             return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            print('is_better')\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            print('not is_better')\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            print('>=')\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - min_delta\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + min_delta\n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameters grad  None\n",
      "p.grad is None\n",
      "p.grad is None\n",
      "p.grad is None\n",
      "Start Time = 16:20:13\n",
      "at epoch 0\n",
      "model parameters grad 0 None\n",
      "model parameters grad 1 None\n",
      "model parameters grad 2 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:206: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:117: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:146: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378124864/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:186: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:286: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:317: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation index  500\n",
      "metrics  1.3690776084744654\n",
      "is None\n",
      "self.best =  1.3690776084744654\n",
      "at epoch 1\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.9932e-04, -4.2914e-05, -1.4079e-04,  ...,  3.6955e-05,\n",
      "         -4.9183e-05,  8.0220e-06],\n",
      "        [ 9.0530e-05,  2.5305e-05,  8.6629e-06,  ...,  7.8929e-06,\n",
      "         -1.0505e-05,  1.7134e-06],\n",
      "        [ 2.4242e-04,  5.3469e-05,  1.5911e-04,  ..., -3.9532e-05,\n",
      "          5.2614e-05, -8.5816e-06],\n",
      "        ...,\n",
      "        [ 5.9499e-14,  1.3669e-14,  3.3863e-14,  ..., -7.3872e-15,\n",
      "          9.8317e-15, -1.6036e-15],\n",
      "        [ 5.9495e-14,  1.3668e-14,  3.3861e-14,  ..., -7.3867e-15,\n",
      "          9.8310e-15, -1.6035e-15],\n",
      "        [ 5.9498e-14,  1.3669e-14,  3.3863e-14,  ..., -7.3872e-15,\n",
      "          9.8316e-15, -1.6036e-15]])\n",
      "model parameters grad 2 tensor([-1.5827e-04, -3.3805e-05,  1.6931e-04,  ...,  3.1639e-14,\n",
      "         3.1637e-14,  3.1639e-14])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.3655000492583873\n",
      "is_better\n",
      "at epoch 2\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.7177e-04, -2.8346e-05, -1.0581e-04,  ...,  2.3849e-05,\n",
      "         -4.6980e-05,  3.1083e-06],\n",
      "        [ 9.9649e-05,  2.4688e-05,  1.7430e-05,  ...,  4.0189e-06,\n",
      "         -7.9170e-06,  5.2381e-07],\n",
      "        [ 2.2358e-04,  3.8675e-05,  1.2824e-04,  ..., -2.7189e-05,\n",
      "          5.3560e-05, -3.5437e-06],\n",
      "        ...,\n",
      "        [ 4.4282e-14,  8.0975e-15,  2.3066e-14,  ..., -4.4376e-15,\n",
      "          8.7417e-15, -5.7837e-16],\n",
      "        [ 4.4282e-14,  8.0975e-15,  2.3066e-14,  ..., -4.4376e-15,\n",
      "          8.7417e-15, -5.7837e-16],\n",
      "        [ 4.4282e-14,  8.0975e-15,  2.3066e-14,  ..., -4.4376e-15,\n",
      "          8.7417e-15, -5.7837e-16]])\n",
      "model parameters grad 2 tensor([-1.7008e-04, -2.8661e-05,  1.9390e-04,  ...,  3.1647e-14,\n",
      "         3.1647e-14,  3.1647e-14])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.3638878933219023\n",
      "is_better\n",
      "at epoch 3\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.5460e-04, -1.9811e-05, -8.3200e-05,  ...,  1.2526e-05,\n",
      "         -4.3655e-05, -5.4425e-08],\n",
      "        [ 9.7213e-05,  1.7697e-05,  2.5361e-05,  ...,  2.2803e-06,\n",
      "         -7.9474e-06, -9.9079e-09],\n",
      "        [ 2.1191e-04,  2.8356e-05,  1.0787e-04,  ..., -1.4844e-05,\n",
      "          5.1733e-05,  6.4495e-08],\n",
      "        ...,\n",
      "        [ 1.0965e-16,  7.4037e-18,  9.3220e-17,  ..., -2.1773e-17,\n",
      "          7.5884e-17,  9.4604e-20],\n",
      "        [ 1.0965e-16,  7.4037e-18,  9.3220e-17,  ..., -2.1773e-17,\n",
      "          7.5884e-17,  9.4604e-20],\n",
      "        [ 1.0965e-16,  7.4037e-18,  9.3220e-17,  ..., -2.1773e-17,\n",
      "          7.5884e-17,  9.4604e-20]])\n",
      "model parameters grad 2 tensor([-1.9287e-04, -3.5112e-05,  2.2856e-04,  ...,  3.3526e-16,\n",
      "         3.3526e-16,  3.3526e-16])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.3627248730770378\n",
      "is_better\n",
      "at epoch 4\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.2634e-04, -1.4384e-05, -6.1375e-05,  ...,  4.1553e-06,\n",
      "         -3.6782e-05, -2.0151e-06],\n",
      "        [ 1.0253e-04,  1.4722e-05,  3.5774e-05,  ...,  6.3613e-07,\n",
      "         -5.6310e-06, -3.0850e-07],\n",
      "        [ 1.9111e-04,  2.2453e-05,  8.9635e-05,  ..., -5.3708e-06,\n",
      "          4.7542e-05,  2.6047e-06],\n",
      "        ...,\n",
      "        [-4.4065e-14, -5.1410e-15, -2.0834e-14,  ...,  1.2859e-15,\n",
      "         -1.1383e-14, -6.2363e-16],\n",
      "        [-4.4065e-14, -5.1410e-15, -2.0834e-14,  ...,  1.2859e-15,\n",
      "         -1.1383e-14, -6.2363e-16],\n",
      "        [-4.4065e-14, -5.1410e-15, -2.0834e-14,  ...,  1.2859e-15,\n",
      "         -1.1383e-14, -6.2363e-16]])\n",
      "model parameters grad 2 tensor([-2.0957e-04, -3.2083e-05,  2.7087e-04,  ..., -6.4855e-14,\n",
      "        -6.4855e-14, -6.4855e-14])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.3619158273519472\n",
      "is_better\n",
      "at epoch 5\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.2412e-04, -1.3740e-05, -5.2560e-05,  ...,  1.2799e-06,\n",
      "         -3.4780e-05, -2.4951e-06],\n",
      "        [ 1.1048e-04,  1.3254e-05,  4.2022e-05,  ...,  1.5329e-07,\n",
      "         -4.1654e-06, -2.9883e-07],\n",
      "        [ 1.8043e-04,  2.0223e-05,  7.5243e-05,  ..., -1.5452e-06,\n",
      "          4.1988e-05,  3.0123e-06],\n",
      "        ...,\n",
      "        [ 1.8706e-14,  2.1183e-15,  7.7001e-15,  ..., -1.3285e-16,\n",
      "          3.6100e-15,  2.5899e-16],\n",
      "        [ 1.8706e-14,  2.1183e-15,  7.7001e-15,  ..., -1.3285e-16,\n",
      "          3.6100e-15,  2.5899e-16],\n",
      "        [ 1.8706e-14,  2.1183e-15,  7.7001e-15,  ..., -1.3285e-16,\n",
      "          3.6100e-15,  2.5899e-16]])\n",
      "model parameters grad 2 tensor([-2.7874e-04, -3.3383e-05,  3.3651e-04,  ...,  2.8932e-14,\n",
      "         2.8932e-14,  2.8932e-14])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.361324046656143\n",
      "is_better\n",
      "at epoch 6\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.2071e-04, -1.4083e-05, -4.7728e-05,  ..., -1.3729e-07,\n",
      "         -3.2319e-05, -2.0582e-06],\n",
      "        [ 1.0831e-04,  1.3231e-05,  4.3171e-05,  ..., -6.4322e-09,\n",
      "         -1.5142e-06, -9.6431e-08],\n",
      "        [ 1.7738e-04,  2.0853e-05,  7.0225e-05,  ...,  1.6716e-07,\n",
      "          3.9352e-05,  2.5061e-06],\n",
      "        ...,\n",
      "        [-4.1456e-14, -4.9125e-15, -1.6435e-14,  ..., -3.0629e-17,\n",
      "         -7.2105e-15, -4.5919e-16],\n",
      "        [-4.1456e-14, -4.9125e-15, -1.6435e-14,  ..., -3.0629e-17,\n",
      "         -7.2105e-15, -4.5919e-16],\n",
      "        [-4.1456e-14, -4.9125e-15, -1.6435e-14,  ..., -3.0629e-17,\n",
      "         -7.2105e-15, -4.5919e-16]])\n",
      "model parameters grad 2 tensor([-3.7562e-04, -1.7598e-05,  4.5736e-04,  ..., -8.3802e-14,\n",
      "        -8.3802e-14, -8.3802e-14])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.360691148735756\n",
      "is_better\n",
      "at epoch 7\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.0549e-04, -1.4675e-05, -3.6418e-05,  ..., -5.7458e-07,\n",
      "         -2.5940e-05, -1.4130e-06],\n",
      "        [ 1.0290e-04,  1.4137e-05,  4.0512e-05,  ..., -1.1801e-08,\n",
      "         -5.3278e-07, -2.9022e-08],\n",
      "        [ 1.6959e-04,  2.3544e-05,  5.9872e-05,  ...,  7.7146e-07,\n",
      "          3.4828e-05,  1.8972e-06],\n",
      "        ...,\n",
      "        [ 1.1332e-15,  1.6148e-16,  2.8270e-16,  ...,  1.8615e-17,\n",
      "          8.4039e-16,  4.5778e-17],\n",
      "        [ 1.1332e-15,  1.6148e-16,  2.8270e-16,  ...,  1.8615e-17,\n",
      "          8.4039e-16,  4.5778e-17],\n",
      "        [ 1.1332e-15,  1.6148e-16,  2.8270e-16,  ...,  1.8615e-17,\n",
      "          8.4039e-16,  4.5778e-17]])\n",
      "model parameters grad 2 tensor([-4.5707e-04, -9.3878e-06,  6.1368e-04,  ...,  1.4808e-14,\n",
      "         1.4808e-14,  1.4808e-14])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.360203825595767\n",
      "is_better\n",
      "at epoch 8\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-1.0034e-04, -1.6030e-05, -3.2840e-05,  ...,  1.8556e-09,\n",
      "         -2.3703e-05, -6.9295e-07],\n",
      "        [ 9.5169e-05,  1.0586e-05,  3.9458e-05,  ...,  9.8375e-11,\n",
      "         -1.2567e-06, -3.6738e-08],\n",
      "        [ 1.5120e-04,  2.2904e-05,  5.1738e-05,  ..., -2.2924e-09,\n",
      "          2.9284e-05,  8.5610e-07],\n",
      "        ...,\n",
      "        [ 3.0381e-14,  4.3055e-15,  1.0930e-14,  ..., -3.4126e-19,\n",
      "          4.3593e-15,  1.2744e-16],\n",
      "        [ 3.0381e-14,  4.3055e-15,  1.0930e-14,  ..., -3.4126e-19,\n",
      "          4.3593e-15,  1.2744e-16],\n",
      "        [ 3.0381e-14,  4.3055e-15,  1.0930e-14,  ..., -3.4126e-19,\n",
      "          4.3593e-15,  1.2744e-16]])\n",
      "model parameters grad 2 tensor([-5.8568e-04, -3.1051e-05,  7.2357e-04,  ...,  1.0771e-13,\n",
      "         1.0771e-13,  1.0771e-13])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.3600015130153922\n",
      "is_better\n",
      "at epoch 9\n",
      "model parameters grad 0 tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "model parameters grad 1 tensor([[-9.7359e-05, -1.6917e-05, -2.5241e-05,  ...,  6.2471e-07,\n",
      "         -2.0468e-05, -1.2056e-06],\n",
      "        [ 8.3664e-05,  6.1713e-06,  2.8584e-05,  ...,  7.3900e-08,\n",
      "         -2.4213e-06, -1.4262e-07],\n",
      "        [ 1.4246e-04,  2.2659e-05,  3.8660e-05,  ..., -7.6118e-07,\n",
      "          2.4940e-05,  1.4690e-06],\n",
      "        ...,\n",
      "        [ 3.3903e-14,  4.8117e-15,  9.6789e-15,  ..., -1.3875e-16,\n",
      "          4.5459e-15,  2.6777e-16],\n",
      "        [ 3.3903e-14,  4.8117e-15,  9.6789e-15,  ..., -1.3875e-16,\n",
      "          4.5459e-15,  2.6777e-16],\n",
      "        [ 3.3903e-14,  4.8117e-15,  9.6789e-15,  ..., -1.3875e-16,\n",
      "          4.5459e-15,  2.6777e-16]])\n",
      "model parameters grad 2 tensor([-7.4565e-04, -8.8207e-05,  9.0855e-04,  ...,  1.6561e-13,\n",
      "         1.6561e-13,  1.6561e-13])\n",
      "training index  300\n",
      "training index  100\n",
      "training index  0\n",
      "training index  400\n",
      "training index  200\n",
      "validation index  500\n",
      "metrics  1.3598244215166846\n",
      "is_better\n",
      "epoch_losses  [1.3713028944947108, 1.360663561815176, 1.3578243279573252, 1.356169481660794, 1.355009331409882, 1.3540682585753419, 1.353168884235526, 1.3523626575806835, 1.351729547207887, 1.3511731072116857]\n",
      " \n",
      "epoch_val_losses  [1.3690776084744654, 1.3655000492583873, 1.3638878933219023, 1.3627248730770378, 1.3619158273519472, 1.361324046656143, 1.360691148735756, 1.360203825595767, 1.3600015130153922, 1.3598244215166846]\n",
      "End Time = 20:06:57\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "# with nn.BCEWithLogitsLoss\n",
    "# With changes for new model with embedding layer\n",
    "# With SMALL dataset\n",
    "# This is the main cell for preparing center words and cotext words and iterates over entire dataset\n",
    "epochs = 10\n",
    "window_size = 2\n",
    "# TRAIN_CSV = 'train1.csv'\n",
    "TRAIN_CSV = 'train_2.csv'\n",
    "\n",
    "# TRAIN_CSV = 'train_original.csv'\n",
    "print_gap = 100\n",
    "early_stopping_patience_value = 5\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# 80% of total data in dataset is used for training and rest 20% will be used for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X = train_test_split (train_df, test_size=0.2 )\n",
    "\n",
    "questions_cols = ['lang1', 'lang2']\n",
    "dataset = train_X\n",
    "epoch_losses = list()\n",
    "epoch_val_losses = list()\n",
    "\n",
    "#keeping vocab size same as embedding dim\n",
    "# VOCAB_SIZE = 200\n",
    "# model_param = ModelParam(101, 101, VOCAB_SIZE + 1, 200, 200)\n",
    "\n",
    "embeddings = torch.tensor(embeddings, dtype=torch.float, requires_grad=True)\n",
    "# embeddings = get_normalized_tensor(embeddings)\n",
    "\n",
    "model_param = ModelParam(101, 101, VOCAB_SIZE + 1, 200, 200, embeddings)\n",
    "\n",
    "# model_param = ModelParam(101, 101, VOCAB_SIZE, 200, 200)\n",
    "\n",
    "model = crossLingualModel(model_param)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# optimal for weight_decay=1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "print('model parameters grad ', list(model.parameters())[0].grad)\n",
    "for p in model.parameters():\n",
    "    if p.grad is not None:\n",
    "        print('grad is not None')\n",
    "        print(p.grad.data)\n",
    "    else:\n",
    "        print('p.grad is None')\n",
    "\n",
    "batch_size = 1\n",
    "number_of_predictions = 0\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Start Time =\", current_time)\n",
    "if_to_store_center_word = False #True\n",
    "# metric = 100\n",
    "\n",
    "es = EarlyStopping(patience=early_stopping_patience_value)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #number_of_predictions = 0\n",
    "#     if(epoch == 99):\n",
    "#         if_to_store_center_word = True\n",
    "    print('at epoch', epoch)\n",
    "    print('model parameters grad 0', list(model.parameters())[0].grad)\n",
    "    print('model parameters grad 1', list(model.parameters())[1].grad)\n",
    "    print('model parameters grad 2', list(model.parameters())[2].grad)\n",
    "    dataset = train_X\n",
    "    intermediate_losses = list()\n",
    "    for index, row in dataset.iterrows():\n",
    "        if (index % print_gap) == 0:\n",
    "            print('training index ', index)\n",
    "        #print('train dataset index', index)\n",
    "        #calculate paragraph vector for entire row\n",
    "#         sent_vector = get_mean_vector(text_to_word_list(row))\n",
    "        sent_vector = row #text_to_word_list(row)\n",
    "        \n",
    "        #print(sent_vector)\n",
    "     \n",
    "        for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "            context_words_lang1_array = []\n",
    "            context_words_lang2_array = []\n",
    "#             for word_lang1 in context_words_lang1:\n",
    "#                 #print('check ', w2v_model.wv[word_lang1])\n",
    "#                 lang1_array = np.array(w2v_model.wv[word_lang1])\n",
    "                \n",
    "#                 #For normalizing array\n",
    "# #                 norm = np.linalg.norm(lang1_array)\n",
    "# #                 lang1_array = lang1_array/norm\n",
    "# #                 lang1_array = get_normalized_array_from_array_using_tensor_formula(lang1_array)\n",
    "#                 context_words_lang1_array.append(lang1_array)\n",
    "           \n",
    "#             for word_lang2 in context_words_lang2:\n",
    "#                 lang2_array = np.array(w2v_model.wv[word_lang2])\n",
    "                \n",
    "#                 #For normalizing array\n",
    "# #                 norm = np.linalg.norm(lang2_array)\n",
    "# #                 lang2_array = lang2_array/norm\n",
    "# #                 lang2_array = get_normalized_array_from_array_using_tensor_formula(lang2_array)\n",
    "#                 context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "#             prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            prediction1, prediction2 = model(context_words_lang1, context_words_lang2, sent_vector)\n",
    "            \n",
    "#             embeddings_output = model.layers[0].get_weights()[0]\n",
    "#             print('context_words_lang1 ',context_words_lang1)\n",
    "#             print('embeddings_output ', embeddings_output)\n",
    "            \n",
    "            number_of_predictions += 1\n",
    "            #print(prediction1)\n",
    "            \n",
    "            #embedding for target word in lang1\n",
    "            target1 = w2v_model.wv[center_word_lang1]\n",
    "#             target1 = np.resize(target1,(1,VOCAB_SIZE + 1))\n",
    "            \n",
    "#             if(if_to_store_center_word):\n",
    "#                 print('checking center word',target1)\n",
    "#                 if_to_store_center_word = False\n",
    "            # For normalizing\n",
    "            #norm1 = np.linalg.norm(target1)\n",
    "            ##target1 = target1/norm1\n",
    "            #print('target norm1 ',norm1)\n",
    "            #print('target1 ',target1)\n",
    "            \n",
    "            #convert prediction1 to np array\n",
    "            #prediction1Array = prediction1.detach().numpy().flatten()\n",
    "            #print(prediction1Array)\n",
    "            #predNorm1 = np.linalg.norm(prediction1Array)\n",
    "            ##prediction1Array = prediction1Array/predNorm1\n",
    "            #print('prediction norm1 ',predNorm1)\n",
    "            \n",
    "            #print('t ',target1)\n",
    "            #print('p ',prediction1Array)\n",
    "            \n",
    "            #mergedTarget1Prediction1 = np.concatenate((target1, prediction1Array))\n",
    "            #print('mergedTarget1Prediction1 ',mergedTarget1Prediction1)\n",
    "            #mergedTarget1Prediction1Norm1 = np.linalg.norm(mergedTarget1Prediction1)\n",
    "            #print('mergedTarget1Prediction1Norm1 ', mergedTarget1Prediction1Norm1)\n",
    "            \n",
    "            #target1 = target1/norm1\n",
    "            \n",
    "            target1 = torch.from_numpy(target1)\n",
    "            target1 = torch.autograd.Variable(target1)\n",
    "            target1 = target1.reshape(1,-1)\n",
    "            \n",
    "            #for normalizing single tensor\n",
    "            \n",
    "            target1 = get_normalized_tensor(target1)\n",
    "            \n",
    "#             prediction1 = prediction1/predNorm1\n",
    "            # Normalize prediction1\n",
    "#             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "#             #x = torch.randn(3, 224, 224)\n",
    "#             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "#           \n",
    "            \n",
    "            #was for normalizing single tensor\n",
    "            \n",
    "            prediction1 = get_normalized_tensor(prediction1)\n",
    "            #print(prediction1)\n",
    "            \n",
    "#             if(epoch == 0):\n",
    "#                 print(prediction1)\n",
    "#                 print(prediction2)\n",
    "                #print(target1)\n",
    "                #print(np.sum(target1))\n",
    "            \n",
    "#             predicted1Score = prediction1.detach().numpy().flatten()\n",
    "#             precision, recall, fscore, support = score(target1Score, predicted1Score)\n",
    "#             print('accuracy fscore ',fscore)\n",
    "            \n",
    "#             train_acc = model.evaluate(prediction1, target1, verbose=0)\n",
    "#             print('train_acc ',train_acc)\n",
    "            #print('p ', prediction1)\n",
    "    \n",
    "            loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "#             loss_lang1 = nn.MSELoss()(prediction1, target1)\n",
    "        \n",
    "           \n",
    "            #embedding for target word in lang2\n",
    "            target2 = w2v_model.wv[center_word_lang2]\n",
    "#             target2 = np.resize(target2,(1,VOCAB_SIZE + 1))\n",
    "            # For normalizing\n",
    "            #norm2 = np.linalg.norm(target2)\n",
    "            #target2 = target2/norm2\n",
    "            \n",
    "            #convert prediction2 to np array\n",
    "            #prediction2Array = prediction2.detach().numpy().flatten()\n",
    "            #print(prediction1Array)\n",
    "            #predNorm2 = np.linalg.norm(prediction2Array)\n",
    "            #mergedTarget2Prediction2 = np.concatenate((target2, prediction2Array))\n",
    "            #print('mergedTarget2Prediction2 ',mergedTarget2Prediction2)\n",
    "            #mergedTarget2Prediction2Norm2 = np.linalg.norm(mergedTarget2Prediction2)\n",
    "            #print('mergedTarget2Prediction2Norm2 ', mergedTarget2Prediction2Norm2)\n",
    "            \n",
    "            #target2 = target2/norm2\n",
    "            \n",
    "            target2 = torch.from_numpy(target2)\n",
    "            target2 = torch.autograd.Variable(target2)\n",
    "            target2 = target2.reshape(1,-1)\n",
    "            \n",
    "            # Was for normalizing single tensor\n",
    "            target2 = get_normalized_tensor(target2)\n",
    "            \n",
    "#             prediction2 = prediction2/predNorm2\n",
    "            \n",
    "            # for normalizing single tensor\n",
    "            prediction2 = get_normalized_tensor(prediction2)\n",
    "            \n",
    "            loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "#             loss_lang2 = nn.MSELoss()(prediction2, target2)\n",
    "            \n",
    "\n",
    "            summed_loss = loss_lang1 + loss_lang2 \n",
    "            intermediate_losses.append(summed_loss.item())\n",
    "            \n",
    "            if(number_of_predictions % batch_size == 0):\n",
    "#                 model.zero_grad()\n",
    "\n",
    "                a = list(model.parameters())[1].clone()\n",
    "#                 loss_lang1.backward()\n",
    "#                 loss_lang2.backward()\n",
    "    \n",
    "                summed_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                b = list(model.parameters())[1].clone()\n",
    "#                 print('if torch.equal(a.data, b.data)', torch.equal(a.data, b.data))\n",
    "            \n",
    "                number_of_predictions = 0\n",
    "                #print('updated model params')\n",
    "            \n",
    "#     print('intermediate_losses')\n",
    "#     print(intermediate_losses)\n",
    "    \n",
    "    epoch_losses.append(np.mean(intermediate_losses))\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        dataset = test_X\n",
    "        intermediate_val_losses = list()\n",
    "        for index, row in dataset.iterrows():\n",
    "            if (index % print_gap) == 0:\n",
    "                print('validation index ', index)\n",
    "            #print('validation dataset index', index)\n",
    "            #calculate paragraph vector for entire row\n",
    "            sent_vector = row #text_to_word_list(row)\n",
    "            #print(sent_vector)\n",
    "\n",
    "            #keeping vocab size same as embedding dim\n",
    "#             model_param = ModelParam(101, 101, 200, 200, 200, sent_vector)\n",
    "#             model = crossLingualModel(model_param)\n",
    "#             optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "            for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "                context_words_lang1_array = []\n",
    "                context_words_lang2_array = []\n",
    "#                 for word_lang1 in context_words_lang1:\n",
    "#                     lang1_array = np.array(w2v_model.wv[word_lang1])\n",
    "\n",
    "#                     #For normalizing array\n",
    "# #                     norm = np.linalg.norm(lang1_array)\n",
    "# #                     lang1_array = lang1_array/norm\n",
    "# #                     lang1_array = get_normalized_array_from_array_using_tensor_formula(lang1_array)\n",
    "#                     context_words_lang1_array.append(lang1_array)\n",
    "\n",
    "#                 for word_lang2 in context_words_lang2:\n",
    "#                     lang2_array = np.array(w2v_model.wv[word_lang2])\n",
    "\n",
    "#                     #For normalizing array\n",
    "# #                     norm = np.linalg.norm(lang2_array)\n",
    "# #                     lang2_array = lang2_array/norm\n",
    "# #                     lang2_array = get_normalized_array_from_array_using_tensor_formula(lang2_array)\n",
    "#                     context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "#                 prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "                prediction1, prediction2 = model(context_words_lang1, context_words_lang2, sent_vector)\n",
    "\n",
    "\n",
    "                #embedding for target word in lang1\n",
    "                target1 = w2v_model.wv[center_word_lang1]\n",
    "#                 target1 = np.resize(target1,(1,VOCAB_SIZE + 1))\n",
    "\n",
    "                # For normalizing\n",
    "#                 norm1 = np.linalg.norm(target1)\n",
    "#                 target1 = target1/norm1\n",
    "\n",
    "                target1 = torch.from_numpy(target1)\n",
    "                target1 = torch.autograd.Variable(target1)\n",
    "                target1 = target1.reshape(1,-1)\n",
    "\n",
    "                # Normalize prediction1\n",
    "    #             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "    #             #x = torch.randn(3, 224, 224)\n",
    "    #             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "                target1 = get_normalized_tensor(target1)\n",
    "                prediction1 = get_normalized_tensor(prediction1)\n",
    "                #print(prediction1)\n",
    "\n",
    "    #             if(epoch == 0):\n",
    "    #                 print(prediction1)\n",
    "    #                 print(prediction2)\n",
    "                    #print(target1)\n",
    "                    #print(np.sum(target1))\n",
    "\n",
    "                loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "#                 loss_lang1 = nn.MSELoss()(prediction1, target1)\n",
    "                \n",
    "\n",
    "                #embedding for target word in lang2\n",
    "                target2 = w2v_model.wv[center_word_lang2]\n",
    "#                 target2 = np.resize(target2,(1,VOCAB_SIZE + 1))\n",
    "\n",
    "                # For normalizing\n",
    "#                 norm2 = np.linalg.norm(target2)\n",
    "#                 target2 = target2/norm2\n",
    "\n",
    "                target2 = torch.from_numpy(target2)\n",
    "                target2 = torch.autograd.Variable(target2)\n",
    "                target2 = target2.reshape(1,-1)\n",
    "                \n",
    "                target2 = get_normalized_tensor(target2)\n",
    "                prediction2 = get_normalized_tensor(prediction2)\n",
    "\n",
    "                loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "#                 loss_lang2 = nn.MSELoss()(prediction2, target2)\n",
    "                \n",
    "\n",
    "                summed_loss = loss_lang1 + loss_lang2  \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                intermediate_val_losses.append(summed_loss.item())\n",
    "                \n",
    "                ## Assuming below lines not needed for Validation. need to confirm\n",
    "                #model.zero_grad()\n",
    "                #summed_loss.backward()\n",
    "                #optimizer.step()\n",
    "\n",
    "#         print('intermediate_val_losses')\n",
    "#         print(intermediate_val_losses)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #num_epochs = 100\n",
    "        #for epoch in range(num_epochs):\n",
    "        #train_one_epoch(model, data_loader)  # train the model for one epoch, on training set\n",
    "        #metric = eval(model, data_loader_dev)  # evalution on dev set (i.e., holdout from training)\n",
    "        epoch_val_losses.append(np.mean(intermediate_val_losses))\n",
    "        \n",
    "        metric = np.mean(intermediate_val_losses)\n",
    "#         print('metric ',metric)\n",
    "#         #metric = metric - 3\n",
    "        if es.step(metric):\n",
    "            print('early stopping at epoch ',epoch)\n",
    "            break  # early stop criterion is met, we can stop now\n",
    "    \n",
    "        \n",
    "        \n",
    "print('epoch_losses ',epoch_losses)\n",
    "print(' ')\n",
    "print('epoch_val_losses ',epoch_val_losses)\n",
    "\n",
    "# print('after 10 epochs')\n",
    "# print(embeddings)\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"End Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'embedding_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e8dec3d1c5d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#keeping vocab size same as embedding dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelParam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossLingualModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'embedding_weights'"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "# Working part with initial model\n",
    "# with nn.BCEWithLogitsLoss\n",
    "# With SMALL dataset\n",
    "# This is the main cell for preparing center words and cotext words and iterates over entire dataset\n",
    "epochs = 100\n",
    "window_size = 2\n",
    "TRAIN_CSV = 'train1.csv'\n",
    "#TRAIN_CSV = 'train_original.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# 80% of total data in dataset is used for training and rest 20% will be used for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X = train_test_split (train_df, test_size=0.2 )\n",
    "\n",
    "questions_cols = ['lang1', 'lang2']\n",
    "dataset = train_X\n",
    "epoch_losses = list()\n",
    "epoch_val_losses = list()\n",
    "\n",
    "#keeping vocab size same as embedding dim\n",
    "model_param = ModelParam(101, 101, 200, 200, 200)\n",
    "model = crossLingualModel(model_param)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# optimal for weight_decay=1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "batch_size = 5\n",
    "number_of_predictions = 0\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Start Time =\", current_time)\n",
    "if_to_store_center_word = False #True\n",
    "# metric = 100\n",
    "\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #number_of_predictions = 0\n",
    "#     if(epoch == 99):\n",
    "#         if_to_store_center_word = True\n",
    "    dataset = train_X\n",
    "    intermediate_losses = list()\n",
    "    for index, row in dataset.iterrows():\n",
    "        #print('train dataset index', index)\n",
    "        #calculate paragraph vector for entire row\n",
    "        sent_vector = get_mean_vector(text_to_word_list(row))\n",
    "        #print(sent_vector)\n",
    "     \n",
    "        for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "            context_words_lang1_array = []\n",
    "            context_words_lang2_array = []\n",
    "            for word_lang1 in context_words_lang1:\n",
    "                #print('check ', w2v_model.wv[word_lang1])\n",
    "                lang1_array = np.array(w2v_model.wv[word_lang1])\n",
    "                \n",
    "                #For normalizing array\n",
    "#                 norm = np.linalg.norm(lang1_array)\n",
    "#                 lang1_array = lang1_array/norm\n",
    "#                 lang1_array = get_normalized_array_from_array_using_tensor_formula(lang1_array)\n",
    "                context_words_lang1_array.append(lang1_array)\n",
    "           \n",
    "            for word_lang2 in context_words_lang2:\n",
    "                lang2_array = np.array(w2v_model.wv[word_lang2])\n",
    "                \n",
    "                #For normalizing array\n",
    "#                 norm = np.linalg.norm(lang2_array)\n",
    "#                 lang2_array = lang2_array/norm\n",
    "#                 lang2_array = get_normalized_array_from_array_using_tensor_formula(lang2_array)\n",
    "                context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "            prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "            number_of_predictions += 1\n",
    "            #print(prediction1)\n",
    "            \n",
    "            #embedding for target word in lang1\n",
    "            target1 = w2v_model.wv[center_word_lang1]\n",
    "#             if(if_to_store_center_word):\n",
    "#                 print('checking center word',target1)\n",
    "#                 if_to_store_center_word = False\n",
    "            # For normalizing\n",
    "            #norm1 = np.linalg.norm(target1)\n",
    "            ##target1 = target1/norm1\n",
    "            #print('target norm1 ',norm1)\n",
    "            #print('target1 ',target1)\n",
    "            \n",
    "            #convert prediction1 to np array\n",
    "            #prediction1Array = prediction1.detach().numpy().flatten()\n",
    "            #print(prediction1Array)\n",
    "            #predNorm1 = np.linalg.norm(prediction1Array)\n",
    "            ##prediction1Array = prediction1Array/predNorm1\n",
    "            #print('prediction norm1 ',predNorm1)\n",
    "            \n",
    "            #print('t ',target1)\n",
    "            #print('p ',prediction1Array)\n",
    "            \n",
    "            #mergedTarget1Prediction1 = np.concatenate((target1, prediction1Array))\n",
    "            #print('mergedTarget1Prediction1 ',mergedTarget1Prediction1)\n",
    "            #mergedTarget1Prediction1Norm1 = np.linalg.norm(mergedTarget1Prediction1)\n",
    "            #print('mergedTarget1Prediction1Norm1 ', mergedTarget1Prediction1Norm1)\n",
    "            \n",
    "            #target1 = target1/norm1\n",
    "            \n",
    "            target1 = torch.from_numpy(target1)\n",
    "            target1 = torch.autograd.Variable(target1)\n",
    "            target1 = target1.reshape(1,-1)\n",
    "            \n",
    "            #for normalizing single tensor\n",
    "            \n",
    "            target1 = get_normalized_tensor(target1)\n",
    "            \n",
    "#             prediction1 = prediction1/predNorm1\n",
    "            # Normalize prediction1\n",
    "#             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "#             #x = torch.randn(3, 224, 224)\n",
    "#             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "#           \n",
    "            \n",
    "            #was for normalizing single tensor\n",
    "            \n",
    "            prediction1 = get_normalized_tensor(prediction1)\n",
    "            #print(prediction1)\n",
    "            \n",
    "#             if(epoch == 0):\n",
    "#                 print(prediction1)\n",
    "#                 print(prediction2)\n",
    "                #print(target1)\n",
    "                #print(np.sum(target1))\n",
    "            \n",
    "#             predicted1Score = prediction1.detach().numpy().flatten()\n",
    "#             precision, recall, fscore, support = score(target1Score, predicted1Score)\n",
    "#             print('accuracy fscore ',fscore)\n",
    "            \n",
    "#             train_acc = model.evaluate(prediction1, target1, verbose=0)\n",
    "#             print('train_acc ',train_acc)\n",
    "            #print('p ', prediction1)\n",
    "            loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "           \n",
    "            #embedding for target word in lang2\n",
    "            target2 = w2v_model.wv[center_word_lang2]\n",
    "            \n",
    "            # For normalizing\n",
    "            #norm2 = np.linalg.norm(target2)\n",
    "            #target2 = target2/norm2\n",
    "            \n",
    "            #convert prediction2 to np array\n",
    "            #prediction2Array = prediction2.detach().numpy().flatten()\n",
    "            #print(prediction1Array)\n",
    "            #predNorm2 = np.linalg.norm(prediction2Array)\n",
    "            #mergedTarget2Prediction2 = np.concatenate((target2, prediction2Array))\n",
    "            #print('mergedTarget2Prediction2 ',mergedTarget2Prediction2)\n",
    "            #mergedTarget2Prediction2Norm2 = np.linalg.norm(mergedTarget2Prediction2)\n",
    "            #print('mergedTarget2Prediction2Norm2 ', mergedTarget2Prediction2Norm2)\n",
    "            \n",
    "            #target2 = target2/norm2\n",
    "            \n",
    "            target2 = torch.from_numpy(target2)\n",
    "            target2 = torch.autograd.Variable(target2)\n",
    "            target2 = target2.reshape(1,-1)\n",
    "            \n",
    "            # Was for normalizing single tensor\n",
    "            target2 = get_normalized_tensor(target2)\n",
    "            \n",
    "#             prediction2 = prediction2/predNorm2\n",
    "            \n",
    "            # for normalizing single tensor\n",
    "            prediction2 = get_normalized_tensor(prediction2)\n",
    "            \n",
    "            loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "\n",
    "            summed_loss = loss_lang1 + loss_lang2 \n",
    "            intermediate_losses.append(summed_loss.item())\n",
    "            \n",
    "            if(number_of_predictions % batch_size == 0):\n",
    "                model.zero_grad()\n",
    "                summed_loss.backward()\n",
    "                optimizer.step()\n",
    "                number_of_predictions = 0\n",
    "                #print('updated model params')\n",
    "            \n",
    "#     print('intermediate_losses')\n",
    "#     print(intermediate_losses)\n",
    "    \n",
    "    epoch_losses.append(np.mean(intermediate_losses))\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        dataset = test_X\n",
    "        intermediate_val_losses = list()\n",
    "        for index, row in dataset.iterrows():\n",
    "            #print('validation dataset index', index)\n",
    "            #calculate paragraph vector for entire row\n",
    "            sent_vector = get_mean_vector(text_to_word_list(row))\n",
    "            #print(sent_vector)\n",
    "\n",
    "            #keeping vocab size same as embedding dim\n",
    "#             model_param = ModelParam(101, 101, 200, 200, 200, sent_vector)\n",
    "#             model = crossLingualModel(model_param)\n",
    "#             optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "            for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "                context_words_lang1_array = []\n",
    "                context_words_lang2_array = []\n",
    "                for word_lang1 in context_words_lang1:\n",
    "                    lang1_array = np.array(w2v_model.wv[word_lang1])\n",
    "\n",
    "                    #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang1_array)\n",
    "#                     lang1_array = lang1_array/norm\n",
    "#                     lang1_array = get_normalized_array_from_array_using_tensor_formula(lang1_array)\n",
    "                    context_words_lang1_array.append(lang1_array)\n",
    "\n",
    "                for word_lang2 in context_words_lang2:\n",
    "                    lang2_array = np.array(w2v_model.wv[word_lang2])\n",
    "\n",
    "                    #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang2_array)\n",
    "#                     lang2_array = lang2_array/norm\n",
    "#                     lang2_array = get_normalized_array_from_array_using_tensor_formula(lang2_array)\n",
    "                    context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "                prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "\n",
    "\n",
    "\n",
    "                #embedding for target word in lang1\n",
    "                target1 = w2v_model.wv[center_word_lang1]\n",
    "\n",
    "                # For normalizing\n",
    "#                 norm1 = np.linalg.norm(target1)\n",
    "#                 target1 = target1/norm1\n",
    "\n",
    "                target1 = torch.from_numpy(target1)\n",
    "                target1 = torch.autograd.Variable(target1)\n",
    "                target1 = target1.reshape(1,-1)\n",
    "\n",
    "                # Normalize prediction1\n",
    "    #             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "    #             #x = torch.randn(3, 224, 224)\n",
    "    #             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "                target1 = get_normalized_tensor(target1)\n",
    "                prediction1 = get_normalized_tensor(prediction1)\n",
    "                #print(prediction1)\n",
    "\n",
    "    #             if(epoch == 0):\n",
    "    #                 print(prediction1)\n",
    "    #                 print(prediction2)\n",
    "                    #print(target1)\n",
    "                    #print(np.sum(target1))\n",
    "\n",
    "                loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "\n",
    "                #embedding for target word in lang2\n",
    "                target2 = w2v_model.wv[center_word_lang2]\n",
    "\n",
    "                # For normalizing\n",
    "#                 norm2 = np.linalg.norm(target2)\n",
    "#                 target2 = target2/norm2\n",
    "\n",
    "                target2 = torch.from_numpy(target2)\n",
    "                target2 = torch.autograd.Variable(target2)\n",
    "                target2 = target2.reshape(1,-1)\n",
    "                \n",
    "                target2 = get_normalized_tensor(target2)\n",
    "                prediction2 = get_normalized_tensor(prediction2)\n",
    "\n",
    "                loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "\n",
    "                summed_loss = loss_lang1 + loss_lang2  \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                intermediate_val_losses.append(summed_loss.item())\n",
    "                \n",
    "                ## Assuming below lines not needed for Validation. need to confirm\n",
    "                #model.zero_grad()\n",
    "                #summed_loss.backward()\n",
    "                #optimizer.step()\n",
    "\n",
    "#         print('intermediate_val_losses')\n",
    "#         print(intermediate_val_losses)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #num_epochs = 100\n",
    "        #for epoch in range(num_epochs):\n",
    "        #train_one_epoch(model, data_loader)  # train the model for one epoch, on training set\n",
    "        #metric = eval(model, data_loader_dev)  # evalution on dev set (i.e., holdout from training)\n",
    "        epoch_val_losses.append(np.mean(intermediate_val_losses))\n",
    "        \n",
    "        metric = np.mean(intermediate_val_losses)\n",
    "#         print('metric ',metric)\n",
    "#         #metric = metric - 3\n",
    "        if es.step(metric):\n",
    "            print('early stopping at epoch ',epoch)\n",
    "            break  # early stop criterion is met, we can stop now\n",
    "    \n",
    "        \n",
    "        \n",
    "print('epoch_losses ',epoch_losses)\n",
    "print(' ')\n",
    "print('epoch_val_losses ',epoch_val_losses)\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"End Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f41b6ef4510>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting in graph for small dataset\n",
    "plt.plot(epoch_losses, label='train losses')\n",
    "plt.plot(epoch_val_losses, label='validation losses')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_losses  [1.3536577944095838]\n",
      " \n",
      "epoch_val_losses  [1.3523250991463052]\n",
      "End Time = 16:50:01\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "# with nn.BCEWithLogitsLoss\n",
    "# With BIG dataset\n",
    "# This is the main cell for preparing center words and cotext words and iterates over entire dataset\n",
    "epochs = 1\n",
    "window_size = 2\n",
    "#TRAIN_CSV = 'train1.csv'\n",
    "TRAIN_CSV = 'train_original.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# 80% of total data in dataset is used for training and rest 20% will be used for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X = train_test_split (train_df, test_size=0.2 )\n",
    "\n",
    "questions_cols = ['lang1', 'lang2']\n",
    "dataset = train_X\n",
    "epoch_losses = list()\n",
    "epoch_val_losses = list()\n",
    "\n",
    "#keeping vocab size same as embedding dim\n",
    "model_param = ModelParam(101, 101, 200, 200, 200)\n",
    "model = crossLingualModel(model_param)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "batch_size = 64\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Start Time =\", current_time)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    number_of_predictions = 0\n",
    "    dataset = train_X\n",
    "    intermediate_losses = list()\n",
    "    for index, row in dataset.iterrows():\n",
    "        if (index % 100) == 0:\n",
    "            print('train dataset index', index)\n",
    "        #calculate paragraph vector for entire row\n",
    "        sent_vector = get_mean_vector(text_to_word_list(row))\n",
    "        #print(sent_vector)\n",
    "     \n",
    "        for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "            context_words_lang1_array = []\n",
    "            context_words_lang2_array = []\n",
    "            for word_lang1 in context_words_lang1:\n",
    "                lang1_array = np.array(w2v_model.wv[word_lang1])\n",
    "                \n",
    "                #For normalizing array\n",
    "#                 norm = np.linalg.norm(lang1_array)\n",
    "#                 lang1_array = lang1_array/norm\n",
    "                \n",
    "                context_words_lang1_array.append(lang1_array)\n",
    "           \n",
    "            for word_lang2 in context_words_lang2:\n",
    "                lang2_array = np.array(w2v_model.wv[word_lang2])\n",
    "                \n",
    "                #For normalizing array\n",
    "#                 norm = np.linalg.norm(lang2_array)\n",
    "#                 lang2_array = lang2_array/norm\n",
    "                \n",
    "                context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "            prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #embedding for target word in lang1\n",
    "            target1 = w2v_model.wv[center_word_lang1]\n",
    "            \n",
    "            # For normalizing\n",
    "#             norm1 = np.linalg.norm(target1)\n",
    "#             target1 = target1/norm1\n",
    "            \n",
    "            target1 = torch.from_numpy(target1)\n",
    "            target1 = torch.autograd.Variable(target1)\n",
    "            target1 = target1.reshape(1,-1)\n",
    "            \n",
    "            target1 = get_normalized_tensor(target1)\n",
    "            \n",
    "            # Normalize prediction1\n",
    "#             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "#             #x = torch.randn(3, 224, 224)\n",
    "#             prediction1 = normPrediction1(prediction1)\n",
    "            \n",
    "            prediction1 = get_normalized_tensor(prediction1)\n",
    "            #print(prediction1)\n",
    "            \n",
    "#             if(epoch == 0):\n",
    "#                 print(prediction1)\n",
    "#                 print(prediction2)\n",
    "                #print(target1)\n",
    "                #print(np.sum(target1))\n",
    "            \n",
    "            loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "           \n",
    "            #embedding for target word in lang2\n",
    "            target2 = w2v_model.wv[center_word_lang2]\n",
    "            \n",
    "            # For normalizing\n",
    "#             norm2 = np.linalg.norm(target2)\n",
    "#             target2 = target2/norm2\n",
    "            \n",
    "            target2 = torch.from_numpy(target2)\n",
    "            target2 = torch.autograd.Variable(target2)\n",
    "            target2 = target2.reshape(1,-1)\n",
    "            \n",
    "            target2 = get_normalized_tensor(target2)\n",
    "        \n",
    "            prediction2 = get_normalized_tensor(prediction2)\n",
    "            \n",
    "            loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "\n",
    "            summed_loss = loss_lang1 + loss_lang2 \n",
    "            intermediate_losses.append(summed_loss.item())\n",
    "            \n",
    "            if(number_of_predictions % batch_size == 0):\n",
    "                model.zero_grad()\n",
    "                summed_loss.backward()\n",
    "                optimizer.step()\n",
    "                number_of_predictions = 0\n",
    "                #print('updated model params')\n",
    "            \n",
    "            \n",
    "#     print('intermediate_losses')\n",
    "#     print(intermediate_losses)\n",
    "    \n",
    "    epoch_losses.append(np.mean(intermediate_losses))\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        dataset = test_X\n",
    "        intermediate_val_losses = list()\n",
    "        for index, row in dataset.iterrows():\n",
    "#             if (index % 10) == 0:\n",
    "#                 print('validation dataset index', index)\n",
    "            #calculate paragraph vector for entire row\n",
    "            sent_vector = get_mean_vector(text_to_word_list(row))\n",
    "            #print(sent_vector)\n",
    "\n",
    "            #keeping vocab size same as embedding dim\n",
    "#             model_param = ModelParam(101, 101, 200, 200, 200, sent_vector)\n",
    "#             model = crossLingualModel(model_param)\n",
    "#             optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "            for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "                context_words_lang1_array = []\n",
    "                context_words_lang2_array = []\n",
    "                for word_lang1 in context_words_lang1:\n",
    "                    lang1_array = np.array(w2v_model.wv[word_lang1])\n",
    "\n",
    "                    #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang1_array)\n",
    "#                     lang1_array = lang1_array/norm\n",
    "\n",
    "                    context_words_lang1_array.append(lang1_array)\n",
    "\n",
    "                for word_lang2 in context_words_lang2:\n",
    "                    lang2_array = np.array(w2v_model.wv[word_lang2])\n",
    "\n",
    "                    #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang2_array)\n",
    "#                     lang2_array = lang2_array/norm\n",
    "\n",
    "                    context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "                prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "\n",
    "\n",
    "\n",
    "                #embedding for target word in lang1\n",
    "                target1 = w2v_model.wv[center_word_lang1]\n",
    "\n",
    "                # For normalizing\n",
    "#                 norm1 = np.linalg.norm(target1)\n",
    "#                 target1 = target1/norm1\n",
    "\n",
    "                target1 = torch.from_numpy(target1)\n",
    "                target1 = torch.autograd.Variable(target1)\n",
    "                target1 = target1.reshape(1,-1)\n",
    "            \n",
    "                target1 = get_normalized_tensor(target1)\n",
    "\n",
    "                # Normalize prediction1\n",
    "    #             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "    #             #x = torch.randn(3, 224, 224)\n",
    "    #             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "                \n",
    "                prediction1 = get_normalized_tensor(prediction1)\n",
    "                #print(prediction1)\n",
    "\n",
    "    #             if(epoch == 0):\n",
    "    #                 print(prediction1)\n",
    "    #                 print(prediction2)\n",
    "                    #print(target1)\n",
    "                    #print(np.sum(target1))\n",
    "\n",
    "                loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "\n",
    "                #embedding for target word in lang2\n",
    "                target2 = w2v_model.wv[center_word_lang2]\n",
    "\n",
    "                # For normalizing\n",
    "#                 norm2 = np.linalg.norm(target2)\n",
    "#                 target2 = target2/norm2\n",
    "\n",
    "                target2 = torch.from_numpy(target2)\n",
    "                target2 = torch.autograd.Variable(target2)\n",
    "                target2 = target2.reshape(1,-1)\n",
    "            \n",
    "                target2 = get_normalized_tensor(target2)\n",
    "                \n",
    "               \n",
    "                prediction2 = get_normalized_tensor(prediction2)\n",
    "\n",
    "                loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "\n",
    "                summed_loss = loss_lang1 + loss_lang2  \n",
    "\n",
    "                \n",
    "                intermediate_val_losses.append(summed_loss.item())\n",
    "                \n",
    "                ## Assuming below lines not needed for Validation. need to confirm\n",
    "                #model.zero_grad()\n",
    "                #summed_loss.backward()\n",
    "                #optimizer.step()\n",
    "\n",
    "#         print('intermediate_val_losses')\n",
    "#         print(intermediate_val_losses)\n",
    "\n",
    "        epoch_val_losses.append(np.mean(intermediate_val_losses))\n",
    "    \n",
    "    \n",
    "print('epoch_losses ',epoch_losses)\n",
    "print(' ')\n",
    "print('epoch_val_losses ',epoch_val_losses)\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"End Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting in graph for LARGE dataset\n",
    "plt.plot(epoch_losses, label='train losses')\n",
    "plt.plot(epoch_val_losses, label='validation losses')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "# Check if word in vocabulary\n",
    "unique_unknown_words = set()\n",
    "def get_word_embedding(word):\n",
    "    if word in w2v_model.wv:\n",
    "        return w2v_model.wv[word]\n",
    "    else:\n",
    "        #print('out of vocabulary word')\n",
    "        unique_unknown_words.add(word)\n",
    "        return np.zeros(w2v_dim)\n",
    "    \n",
    "# print('zero array ', len(np.array(get_word_embedding('TEST'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Testing\n",
    "# This is the main cell for preparing center words and cotext words and iterates over entire dataset\n",
    "# epochs = 10\n",
    "window_size = 2\n",
    "#TEST_CSV = 'test1.csv'\n",
    "TEST_CSV = 'test_original.csv'\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# 80% of total data in dataset is used for training and rest 20% will be used for testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_X, test_X = train_test_split (train_df, test_size=0.2 )\n",
    "\n",
    "questions_cols = ['lang1', 'lang2']\n",
    "dataset = test_df\n",
    "\n",
    "epoch_test_losses = list()\n",
    "\n",
    "unique_total_words = set()\n",
    "\n",
    "\n",
    "#keeping vocab size same as embedding dim\n",
    "# model_param = ModelParam(101, 101, 200, 200, 200)\n",
    "# model = crossLingualModel(model_param)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "# Testing\n",
    "with torch.no_grad():\n",
    "    \n",
    "    intermediate_test_losses = list()\n",
    "    for index, row in dataset.iterrows():\n",
    "        #if (index % 10) == 0:\n",
    "        print('test dataset index', index)\n",
    "        #calculate paragraph vector for entire row\n",
    "        sent_vector = get_mean_vector(text_to_word_list(row))\n",
    "        #print(sent_vector)\n",
    "\n",
    "        #keeping vocab size same as embedding dim\n",
    "#             model_param = ModelParam(101, 101, 200, 200, 200, sent_vector)\n",
    "#             model = crossLingualModel(model_param)\n",
    "#             optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "            context_words_lang1_array = []\n",
    "            context_words_lang2_array = []\n",
    "            for word_lang1 in context_words_lang1:\n",
    "                unique_total_words.add(word_lang1)\n",
    "                #ADD CHECK For out of vocabulary word\n",
    "                lang1_array = np.array(get_word_embedding(word_lang1))\n",
    "\n",
    "                #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang1_array)\n",
    "#                     lang1_array = lang1_array/norm\n",
    "\n",
    "                context_words_lang1_array.append(lang1_array)\n",
    "\n",
    "            for word_lang2 in context_words_lang2:\n",
    "                unique_total_words.add(word_lang2)\n",
    "                #ADD CHECK For out of vocabulary word\n",
    "                lang2_array = np.array(get_word_embedding(word_lang2))\n",
    "\n",
    "                #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang2_array)\n",
    "#                     lang2_array = lang2_array/norm\n",
    "\n",
    "                context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "            prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "\n",
    "\n",
    "\n",
    "            #embedding for target word in lang1\n",
    "            #ADD CHECK For out of vocabulary word\n",
    "            target1 = get_word_embedding(center_word_lang1)\n",
    "            \n",
    "            unique_total_words.add(center_word_lang1)\n",
    "            \n",
    "\n",
    "            # For normalizing\n",
    "#                 norm1 = np.linalg.norm(target1)\n",
    "#                 target1 = target1/norm1\n",
    "\n",
    "            target1 = torch.from_numpy(target1)\n",
    "            target1 = torch.autograd.Variable(target1)\n",
    "            target1 = target1.reshape(1,-1)\n",
    "\n",
    "            target1 = get_normalized_tensor(target1)\n",
    "\n",
    "            # Normalize prediction1\n",
    "#             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "#             #x = torch.randn(3, 224, 224)\n",
    "#             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "\n",
    "            prediction1 = get_normalized_tensor(prediction1)\n",
    "            #print(prediction1)\n",
    "\n",
    "#             if(epoch == 0):\n",
    "#                 print(prediction1)\n",
    "#                 print(prediction2)\n",
    "                #print(target1)\n",
    "                #print(np.sum(target1))\n",
    "\n",
    "            loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "\n",
    "            #embedding for target word in lang2\n",
    "            #ADD CHECK For out of vocabulary word\n",
    "            target2 = get_word_embedding(center_word_lang2)\n",
    "            \n",
    "            unique_total_words.add(center_word_lang2)\n",
    "\n",
    "            # For normalizing\n",
    "#                 norm2 = np.linalg.norm(target2)\n",
    "#                 target2 = target2/norm2\n",
    "\n",
    "            target2 = torch.from_numpy(target2)\n",
    "            target2 = torch.autograd.Variable(target2)\n",
    "            target2 = target2.reshape(1,-1)\n",
    "\n",
    "            target2 = get_normalized_tensor(target2)\n",
    "\n",
    "\n",
    "            prediction2 = get_normalized_tensor(prediction2)\n",
    "\n",
    "            loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "\n",
    "            summed_loss = loss_lang1 + loss_lang2  \n",
    "\n",
    "\n",
    "            intermediate_test_losses.append(summed_loss.item())\n",
    "\n",
    "            ## Assuming below lines not needed for test. need to confirm\n",
    "            #model.zero_grad()\n",
    "            #summed_loss.backward()\n",
    "            #optimizer.step()\n",
    "\n",
    "    print('intermediate_test_losses')\n",
    "    print(intermediate_test_losses)\n",
    "\n",
    "    epoch_test_losses.append(np.mean(intermediate_test_losses))\n",
    "    \n",
    "\n",
    "print('epoch_test_losses ',epoch_test_losses)\n",
    "print('unique_total_words = ',len(unique_total_words))\n",
    "print('unique_unknown_words = ',len(unique_unknown_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output  tensor([[6.8440e-01, 4.4021e-02, 1.9737e-01, 8.2299e-02, 7.6318e-01, 9.8808e-02,\n",
      "         3.0216e-03, 4.1444e-02, 5.3627e-02, 1.9861e-01, 3.5944e-01, 2.6297e-01,\n",
      "         1.1134e-01, 9.6503e-02, 1.6601e-01, 1.6606e-01, 1.5104e-01, 2.6335e-01,\n",
      "         2.5068e-01, 7.9103e-02, 9.5673e-01, 7.2874e-01, 2.4573e-01, 3.0512e-01,\n",
      "         8.3010e-01, 6.0079e-03, 1.4325e-02, 3.0978e-02, 6.8462e-01, 4.1286e-01,\n",
      "         2.1328e-02, 2.0172e-01, 2.1426e-02, 9.9420e-01, 1.9171e-01, 2.2902e-02,\n",
      "         1.5727e-01, 6.9884e-01, 3.1535e-01, 1.9871e-01, 2.7940e-02, 1.7599e-02,\n",
      "         4.3735e-02, 2.9893e-01, 3.8005e-01, 3.0119e-01, 4.0379e-02, 3.4043e-01,\n",
      "         5.1567e-01, 3.5169e-01, 7.9269e-02, 4.9033e-01, 5.4237e-01, 3.9473e-01,\n",
      "         2.1534e-02, 6.8075e-03, 6.5596e-01, 6.9981e-02, 9.0846e-02, 3.4336e-01,\n",
      "         4.9533e-02, 8.2195e-01, 1.8630e-01, 1.1219e-01, 6.0581e-02, 2.3383e-02,\n",
      "         5.3251e-01, 3.5870e-02, 7.1543e-01, 8.1446e-01, 6.4794e-01, 2.2682e-01,\n",
      "         1.8775e-02, 6.4348e-01, 5.9329e-02, 3.9570e-01, 6.0650e-01, 1.9509e-01,\n",
      "         2.1633e-01, 8.5649e-01, 5.7428e-02, 5.2542e-03, 0.0000e+00, 3.8119e-02,\n",
      "         5.9433e-01, 3.0236e-02, 1.2972e-01, 1.9983e-01, 3.3305e-01, 2.4219e-02,\n",
      "         4.3895e-01, 7.8122e-02, 7.7134e-02, 7.8908e-01, 1.2523e-02, 2.5269e-01,\n",
      "         7.6078e-01, 1.7143e-01, 5.7266e-01, 3.1955e-01, 2.8920e-01, 9.9470e-01,\n",
      "         2.4608e-01, 7.9807e-01, 2.6500e-01, 8.7834e-02, 2.2191e-03, 3.8580e-01,\n",
      "         2.4402e-02, 1.5631e-01, 3.1957e-02, 4.5099e-01, 2.9930e-01, 2.2245e-02,\n",
      "         3.4620e-01, 5.2362e-01, 1.3336e-01, 4.6760e-02, 3.5303e-01, 3.3654e-02,\n",
      "         8.1489e-01, 2.8036e-02, 1.9129e-02, 1.1203e-01, 9.4287e-01, 5.2645e-01,\n",
      "         6.8328e-01, 2.4409e-02, 5.2776e-01, 1.4068e-01, 1.5244e-02, 4.2113e-01,\n",
      "         7.7957e-02, 3.1180e-03, 5.7933e-01, 2.9404e-02, 7.3170e-01, 1.3212e-01,\n",
      "         5.4340e-01, 7.1232e-01, 2.4023e-02, 2.5065e-02, 3.4884e-01, 6.0066e-01,\n",
      "         6.4743e-01, 2.5999e-02, 5.0701e-01, 4.8454e-02, 1.4055e-01, 1.0000e+00,\n",
      "         1.1701e-02, 2.0130e-02, 1.2579e-02, 2.5059e-04, 7.6935e-01, 1.0997e-01,\n",
      "         5.3168e-01, 6.1174e-02, 5.1899e-02, 9.7853e-01, 3.1992e-01, 5.6700e-01,\n",
      "         3.4654e-02, 2.9285e-01, 7.4425e-02, 1.0021e-02, 6.9652e-01, 2.9755e-01,\n",
      "         2.0506e-01, 3.1129e-01, 1.2247e-01, 4.6368e-02, 9.9441e-01, 3.4040e-01,\n",
      "         6.8942e-03, 1.1172e-01, 7.2127e-02, 1.5411e-01, 4.4650e-02, 5.7630e-01,\n",
      "         7.5186e-01, 3.3323e-01, 2.0747e-01, 6.2380e-01, 2.5788e-02, 9.8538e-02,\n",
      "         1.5279e-01, 5.7964e-02, 5.7524e-01, 1.8238e-01, 2.0451e-02, 2.4610e-01,\n",
      "         3.8526e-02, 1.6010e-02, 3.1148e-02, 6.4880e-01, 1.8722e-02, 3.3066e-01,\n",
      "         3.8022e-01, 3.5218e-02]])\n",
      "ground truth  tensor([[0.5220, 0.5612, 0.4212, 0.4908, 0.6386, 0.6321, 0.1384, 0.4571, 0.6167,\n",
      "         0.4451, 0.5280, 0.3924, 0.5102, 0.5045, 0.6981, 0.2725, 0.7052, 0.5363,\n",
      "         0.5879, 0.4894, 1.0000, 0.6467, 0.7257, 0.3912, 0.7098, 0.0905, 0.5218,\n",
      "         0.3026, 0.7320, 0.7440, 0.2596, 0.6396, 0.3372, 0.6240, 0.5926, 0.2395,\n",
      "         0.5518, 0.6059, 0.4159, 0.5064, 0.5547, 0.4291, 0.4782, 0.7182, 0.4595,\n",
      "         0.6184, 0.8245, 0.5095, 0.7433, 0.5298, 0.7017, 0.8651, 0.7245, 0.5914,\n",
      "         0.3376, 0.2337, 0.7765, 0.4327, 0.6968, 0.5907, 0.5687, 0.8241, 0.3621,\n",
      "         0.6873, 0.4966, 0.3775, 0.6422, 0.5270, 0.5443, 0.7360, 0.4029, 0.6576,\n",
      "         0.4201, 0.5295, 0.6217, 0.3735, 0.9547, 0.4052, 0.4871, 0.8389, 0.4771,\n",
      "         0.4845, 0.3775, 0.4647, 0.7395, 0.4706, 0.3006, 0.5687, 0.4517, 0.2163,\n",
      "         0.7547, 0.6064, 0.6564, 0.8944, 0.4090, 0.7100, 0.6526, 0.4977, 0.5950,\n",
      "         0.7762, 0.6679, 0.6980, 0.7165, 0.5843, 0.4843, 0.2618, 0.2458, 0.5456,\n",
      "         0.2452, 0.5136, 0.4654, 0.5078, 0.5068, 0.5346, 0.6053, 0.4315, 0.7699,\n",
      "         0.3727, 0.5162, 0.4612, 0.7915, 0.4086, 0.5358, 0.4552, 0.6942, 0.5738,\n",
      "         0.5915, 0.6467, 0.6000, 0.8045, 0.4235, 0.5499, 0.3165, 0.4394, 0.8732,\n",
      "         0.4320, 0.8811, 0.6517, 0.6975, 0.7122, 0.3137, 0.3297, 0.5087, 0.8299,\n",
      "         0.7620, 0.3706, 0.6807, 0.6229, 0.4125, 0.9488, 0.0000, 0.6393, 0.3066,\n",
      "         0.3358, 0.7502, 0.6321, 0.7717, 0.5153, 0.5567, 0.8001, 0.4436, 0.5344,\n",
      "         0.6506, 0.5650, 0.6290, 0.3794, 0.6696, 0.6855, 0.6689, 0.7038, 0.5673,\n",
      "         0.6139, 0.8180, 0.7283, 0.3359, 0.4997, 0.5372, 0.6826, 0.5041, 0.8022,\n",
      "         0.8178, 0.7438, 0.4192, 0.6477, 0.3285, 0.3230, 0.5457, 0.3393, 0.7328,\n",
      "         0.6422, 0.3205, 0.8538, 0.2410, 0.4186, 0.4917, 0.8080, 0.2567, 0.8150,\n",
      "         0.5904, 0.6505]])\n",
      "loss x86 tensor(0.6660)\n",
      "output  tensor([[0.0369, 0.1912, 0.0975, 0.2274, 0.0186, 0.0828, 0.0666, 0.1003, 0.0512,\n",
      "         0.1186, 0.0304, 0.1462, 0.0369, 0.0662, 0.2486, 0.6199, 0.0384, 0.4338,\n",
      "         0.0434, 0.3568, 0.0095, 0.0764, 0.3471, 0.0121, 0.0082, 0.0383, 0.0288,\n",
      "         0.5643, 0.5300, 0.4881, 0.1135, 0.0928, 0.0587, 0.1508, 0.0950, 0.5109,\n",
      "         0.4315, 0.0195, 0.0600, 0.2453, 0.0553, 0.4245, 0.8550, 0.0319, 0.6703,\n",
      "         0.0926, 0.4937, 0.4023, 0.0394, 0.0262, 0.5287, 0.4211, 0.5599, 0.8082,\n",
      "         0.0770, 0.2862, 0.0301, 0.3933, 0.0502, 0.0303, 0.7794, 0.0776, 0.0876,\n",
      "         0.6224, 0.0615, 0.3098, 0.0152, 0.0263, 0.0336, 0.1615, 0.1368, 0.2795,\n",
      "         0.0319, 0.0261, 0.0306, 0.2247, 0.0352, 0.0318, 0.0524, 0.0494, 0.6713,\n",
      "         0.1223, 0.2914, 0.0333, 0.1166, 0.2998, 0.4981, 0.0511, 0.1898, 0.7289,\n",
      "         0.0953, 0.1293, 0.7426, 0.1918, 0.0976, 0.0357, 0.0241, 0.3981, 0.1291,\n",
      "         0.5936, 0.2081, 0.0297, 0.3761, 0.0124, 0.0419, 1.0000, 0.0615, 0.0254,\n",
      "         0.1531, 0.0455, 0.0347, 0.2667, 0.2346, 0.0265, 0.3061, 0.0309, 0.7572,\n",
      "         0.3963, 0.5874, 0.5029, 0.0283, 0.8292, 0.0345, 0.0337, 0.0000, 0.3012,\n",
      "         0.0388, 0.0321, 0.0751, 0.1897, 0.2355, 0.2448, 0.0268, 0.1919, 0.0205,\n",
      "         0.4949, 0.0173, 0.0505, 0.3007, 0.0634, 0.1862, 0.4467, 0.0511, 0.3405,\n",
      "         0.4656, 0.6113, 0.1259, 0.8378, 0.0275, 0.0072, 0.5047, 0.0395, 0.7859,\n",
      "         0.0969, 0.0565, 0.3476, 0.5665, 0.0748, 0.1695, 0.0033, 0.0469, 0.0134,\n",
      "         0.0703, 0.7088, 0.9036, 0.7480, 0.2210, 0.2049, 0.0689, 0.1679, 0.2527,\n",
      "         0.1465, 0.0026, 0.0541, 0.1124, 0.1795, 0.5566, 0.2557, 0.1147, 0.2086,\n",
      "         0.0797, 0.0688, 0.3478, 0.2194, 0.1069, 0.0609, 0.0635, 0.7532, 0.4982,\n",
      "         0.3699, 0.0338, 0.0553, 0.0297, 0.6174, 0.5565, 0.2947, 0.0319, 0.0271,\n",
      "         0.2788, 0.0460]])\n",
      "ground truth  tensor([[0.0000e+00, 5.1554e-01, 5.5249e-01, 3.8334e-01, 4.8682e-01, 3.4161e-01,\n",
      "         4.4455e-01, 6.0878e-01, 3.8187e-01, 6.8955e-01, 2.7584e-01, 3.6454e-01,\n",
      "         1.0314e-03, 8.3767e-01, 3.7332e-01, 9.8485e-01, 2.3115e-01, 3.6812e-01,\n",
      "         3.0635e-01, 5.5453e-01, 6.0839e-01, 5.3415e-01, 2.7342e-01, 1.3586e-01,\n",
      "         2.2430e-02, 3.2756e-01, 4.2809e-01, 6.9445e-01, 9.9145e-01, 5.0253e-01,\n",
      "         6.9348e-01, 5.5321e-01, 5.3931e-01, 4.7924e-01, 4.5125e-01, 6.6055e-01,\n",
      "         4.1638e-01, 8.9961e-02, 6.1209e-01, 5.2696e-01, 6.0208e-01, 7.4477e-01,\n",
      "         7.8823e-01, 4.5215e-01, 9.5990e-01, 3.7070e-01, 8.0817e-01, 6.6833e-01,\n",
      "         6.6874e-02, 5.9895e-01, 4.8371e-01, 6.8512e-01, 5.5631e-01, 9.5217e-01,\n",
      "         2.7756e-01, 5.1664e-01, 5.1464e-01, 5.2856e-01, 5.3520e-01, 4.2624e-01,\n",
      "         8.0951e-01, 5.0056e-01, 6.9964e-01, 5.4154e-01, 5.7862e-01, 8.4104e-01,\n",
      "         4.5289e-01, 6.0754e-01, 3.8312e-01, 6.8512e-01, 4.9850e-01, 5.2478e-01,\n",
      "         3.4556e-01, 1.5930e-01, 6.0306e-01, 5.5941e-01, 1.8802e-01, 5.6750e-01,\n",
      "         8.7371e-01, 2.2347e-01, 5.4912e-01, 7.6155e-01, 1.1123e-01, 1.1631e-01,\n",
      "         6.0945e-01, 4.8366e-01, 7.5081e-01, 4.6937e-01, 7.8652e-01, 4.2922e-01,\n",
      "         4.4089e-01, 6.1904e-01, 6.2702e-01, 4.9756e-01, 6.9028e-01, 7.3422e-01,\n",
      "         2.1738e-01, 5.9318e-01, 5.7505e-01, 5.8237e-01, 3.6847e-01, 3.6269e-01,\n",
      "         7.3840e-01, 3.0333e-04, 1.6777e-01, 8.4104e-01, 1.6748e-01, 4.4473e-01,\n",
      "         6.0693e-01, 1.7590e-01, 5.4808e-01, 5.3651e-01, 4.6416e-01, 3.2241e-01,\n",
      "         6.1724e-01, 5.2251e-01, 7.1363e-01, 7.4322e-01, 7.2954e-01, 3.5735e-01,\n",
      "         6.0422e-01, 8.4906e-01, 4.8279e-01, 4.0791e-01, 2.7026e-01, 2.7541e-01,\n",
      "         5.1458e-01, 3.4353e-01, 4.7158e-01, 9.1599e-01, 8.0487e-01, 6.6310e-01,\n",
      "         6.2000e-02, 4.4893e-01, 1.4473e-01, 6.5558e-01, 3.7677e-01, 4.9008e-01,\n",
      "         4.5282e-01, 3.6083e-01, 6.5392e-01, 2.2767e-01, 5.5808e-01, 5.9391e-01,\n",
      "         4.8930e-01, 7.2150e-01, 6.0553e-01, 7.6827e-01, 1.8247e-01, 3.6379e-01,\n",
      "         6.6408e-01, 3.8604e-01, 1.0000e+00, 8.3176e-01, 3.6033e-01, 6.8487e-01,\n",
      "         6.3082e-01, 6.1084e-01, 5.6767e-01, 5.5329e-01, 2.4969e-01, 7.0844e-02,\n",
      "         3.9927e-01, 7.0172e-01, 6.9625e-01, 7.8795e-01, 1.4692e-01, 9.4823e-01,\n",
      "         3.7251e-01, 4.9812e-01, 1.6274e-01, 3.9599e-01, 4.4634e-01, 4.3193e-01,\n",
      "         4.5962e-01, 5.0471e-01, 7.3153e-01, 3.7252e-01, 3.1056e-01, 6.0633e-01,\n",
      "         6.7229e-01, 1.8320e-01, 2.7148e-01, 8.2756e-01, 6.7123e-01, 6.9984e-01,\n",
      "         3.4377e-01, 6.7719e-01, 5.2191e-01, 9.4050e-01, 3.7207e-01, 4.7043e-01,\n",
      "         1.2609e-01, 5.0841e-01, 5.3463e-01, 5.6274e-01, 2.5550e-01, 5.1074e-01,\n",
      "         4.4639e-01, 5.0456e-01]])\n",
      "loss arm tensor(0.6660)\n",
      "output  tensor([[0.5061, 0.0667, 0.1445, 0.0822, 0.6909, 0.0879, 0.0186, 0.0225, 0.0639,\n",
      "         0.1389, 0.3103, 0.2790, 0.0980, 0.1099, 0.0983, 0.1806, 0.1761, 0.2291,\n",
      "         0.1752, 0.0885, 0.7875, 0.8595, 0.1880, 0.2008, 0.7115, 0.0204, 0.0264,\n",
      "         0.0851, 0.6375, 0.3865, 0.0416, 0.1676, 0.0438, 1.0000, 0.2591, 0.0891,\n",
      "         0.1331, 0.6824, 0.2988, 0.2078, 0.0369, 0.0640, 0.1420, 0.1833, 0.2272,\n",
      "         0.2159, 0.1089, 0.2407, 0.4809, 0.2639, 0.1269, 0.5565, 0.5189, 0.4813,\n",
      "         0.0343, 0.1021, 0.5868, 0.0480, 0.0532, 0.2756, 0.1300, 0.6459, 0.1744,\n",
      "         0.1341, 0.0436, 0.0408, 0.5078, 0.0232, 0.5216, 0.5730, 0.5139, 0.2041,\n",
      "         0.0288, 0.4952, 0.0341, 0.3474, 0.4255, 0.1505, 0.1281, 0.7545, 0.1746,\n",
      "         0.0385, 0.0471, 0.0306, 0.4894, 0.0529, 0.2114, 0.1577, 0.3658, 0.1148,\n",
      "         0.3734, 0.1536, 0.1608, 0.6260, 0.0159, 0.1754, 0.6980, 0.2840, 0.4256,\n",
      "         0.3289, 0.3878, 0.8998, 0.2480, 0.6123, 0.2500, 0.1816, 0.0000, 0.2913,\n",
      "         0.0366, 0.2106, 0.0279, 0.4602, 0.2725, 0.0254, 0.3703, 0.4351, 0.1740,\n",
      "         0.0632, 0.1822, 0.1838, 0.5756, 0.1321, 0.0228, 0.1176, 0.8352, 0.4885,\n",
      "         0.5958, 0.0179, 0.4458, 0.1572, 0.0448, 0.4139, 0.0778, 0.0385, 0.4626,\n",
      "         0.0406, 0.6776, 0.1084, 0.4519, 0.5262, 0.0452, 0.0696, 0.3321, 0.4119,\n",
      "         0.4909, 0.0763, 0.4037, 0.0809, 0.1146, 0.8810, 0.0456, 0.0284, 0.0931,\n",
      "         0.0334, 0.5545, 0.1300, 0.6087, 0.0554, 0.0049, 0.8220, 0.2617, 0.4550,\n",
      "         0.0415, 0.2423, 0.0817, 0.0507, 0.5561, 0.2783, 0.1426, 0.1525, 0.1518,\n",
      "         0.0559, 0.9467, 0.1994, 0.0287, 0.1136, 0.0959, 0.1305, 0.0431, 0.4789,\n",
      "         0.6188, 0.2339, 0.2170, 0.5434, 0.0411, 0.0714, 0.1429, 0.1260, 0.3890,\n",
      "         0.1699, 0.0240, 0.2397, 0.0343, 0.0865, 0.0856, 0.5451, 0.0275, 0.1982,\n",
      "         0.3925, 0.0364]])\n",
      "ground truth  tensor([[0.6084, 0.2887, 0.5319, 0.3729, 0.6847, 0.2170, 0.3215, 0.5750, 0.4166,\n",
      "         0.2630, 0.4061, 0.6607, 0.7321, 0.5879, 0.6917, 0.5403, 0.7346, 0.2162,\n",
      "         0.7370, 0.2941, 0.7210, 0.9089, 0.9439, 0.6521, 0.9467, 0.0785, 0.5653,\n",
      "         0.3640, 0.4771, 0.7077, 0.5559, 0.4183, 0.2747, 0.6932, 0.5073, 0.3847,\n",
      "         0.6046, 0.7288, 0.4223, 0.6335, 0.3429, 0.4027, 0.5523, 0.3610, 0.3928,\n",
      "         0.5299, 0.2344, 0.6316, 0.8597, 0.9465, 0.4107, 0.9783, 0.4305, 0.6373,\n",
      "         0.2912, 0.2539, 0.7417, 0.3076, 0.5324, 0.8254, 0.3255, 0.9080, 0.6608,\n",
      "         0.4647, 0.4847, 0.5119, 0.7013, 0.4000, 0.2861, 0.7910, 0.9326, 0.6358,\n",
      "         0.2132, 0.7219, 0.7244, 1.0000, 0.5158, 0.6469, 0.5554, 0.5999, 0.4682,\n",
      "         0.5908, 0.1710, 0.4958, 0.5981, 0.0687, 0.2162, 0.9975, 0.3100, 0.3358,\n",
      "         0.7312, 0.3849, 0.6099, 0.8039, 0.0716, 0.5979, 0.7208, 0.9557, 0.5744,\n",
      "         0.6210, 0.6670, 0.8402, 0.6513, 0.7771, 0.6261, 0.4310, 0.3481, 0.5805,\n",
      "         0.3033, 0.5525, 0.4797, 0.9800, 0.6877, 0.4755, 0.4830, 0.4810, 0.4095,\n",
      "         0.1371, 0.4867, 0.4932, 0.3887, 0.0000, 0.3149, 0.4435, 0.7842, 0.8611,\n",
      "         0.6073, 0.2471, 0.6441, 0.2783, 0.3184, 0.4410, 0.3672, 0.4216, 0.7641,\n",
      "         0.5800, 0.7230, 0.6550, 0.8391, 0.6434, 0.2170, 0.2176, 0.6292, 0.6498,\n",
      "         0.2876, 0.4615, 0.5593, 0.3740, 0.1865, 0.8223, 0.1793, 0.4220, 0.1149,\n",
      "         0.5509, 0.7995, 0.4909, 0.7740, 0.2316, 0.3935, 0.6344, 0.8250, 0.8569,\n",
      "         0.7388, 0.3159, 0.8392, 0.2288, 0.5482, 0.5621, 0.3688, 0.2613, 0.6754,\n",
      "         0.4157, 0.5246, 0.6866, 0.3510, 0.4285, 0.2781, 0.2645, 0.2472, 0.6872,\n",
      "         0.9858, 0.4660, 0.7344, 0.6830, 0.4804, 0.2585, 0.9168, 0.5177, 0.4807,\n",
      "         0.5949, 0.2907, 0.3385, 0.5833, 0.6585, 0.1949, 0.6037, 0.3424, 0.4027,\n",
      "         0.6770, 0.2668]])\n",
      "loss x86 tensor(0.6729)\n",
      "output  tensor([[0.0308, 0.1935, 0.0939, 0.2055, 0.0243, 0.0488, 0.0345, 0.1137, 0.0176,\n",
      "         0.0903, 0.0106, 0.1092, 0.0162, 0.0701, 0.2091, 0.7096, 0.0223, 0.5291,\n",
      "         0.0442, 0.4013, 0.0077, 0.0638, 0.3542, 0.0049, 0.0095, 0.0208, 0.0154,\n",
      "         0.5954, 0.5299, 0.6116, 0.1356, 0.0479, 0.0684, 0.1193, 0.0653, 0.5847,\n",
      "         0.3738, 0.0089, 0.0322, 0.2899, 0.0597, 0.4886, 0.8932, 0.0218, 0.6512,\n",
      "         0.0769, 0.5808, 0.4744, 0.0197, 0.0114, 0.5630, 0.3445, 0.5563, 0.8345,\n",
      "         0.0598, 0.3411, 0.0393, 0.2518, 0.0264, 0.0087, 0.8626, 0.0422, 0.0747,\n",
      "         0.6047, 0.0317, 0.2770, 0.0068, 0.0189, 0.0213, 0.0744, 0.0624, 0.1869,\n",
      "         0.0259, 0.0120, 0.0231, 0.1663, 0.0145, 0.0114, 0.0387, 0.0388, 0.6857,\n",
      "         0.1821, 0.3042, 0.0215, 0.1255, 0.3462, 0.5936, 0.0476, 0.1144, 0.8004,\n",
      "         0.1125, 0.2552, 0.8074, 0.1419, 0.0481, 0.0179, 0.0148, 0.3526, 0.1623,\n",
      "         0.6917, 0.2351, 0.0256, 0.4029, 0.0071, 0.0244, 1.0000, 0.0540, 0.0092,\n",
      "         0.1079, 0.0136, 0.0169, 0.3264, 0.1924, 0.0129, 0.4062, 0.0277, 0.8365,\n",
      "         0.3481, 0.5236, 0.5538, 0.0303, 0.8624, 0.0187, 0.0051, 0.0000, 0.1856,\n",
      "         0.0089, 0.0138, 0.0595, 0.2224, 0.1493, 0.1861, 0.0064, 0.2235, 0.0052,\n",
      "         0.4258, 0.0229, 0.0275, 0.0846, 0.0311, 0.1758, 0.4066, 0.0300, 0.3363,\n",
      "         0.4711, 0.6018, 0.0749, 0.6841, 0.0096, 0.0056, 0.5155, 0.0128, 0.8019,\n",
      "         0.1114, 0.0332, 0.3692, 0.6509, 0.0633, 0.1460, 0.0060, 0.0359, 0.0021,\n",
      "         0.0624, 0.7449, 0.8365, 0.7567, 0.3266, 0.3034, 0.0613, 0.1354, 0.2246,\n",
      "         0.0525, 0.0045, 0.0104, 0.1046, 0.0906, 0.6209, 0.1348, 0.1004, 0.2398,\n",
      "         0.0972, 0.0440, 0.3789, 0.2094, 0.1056, 0.0301, 0.0325, 0.7889, 0.3861,\n",
      "         0.3101, 0.0173, 0.0479, 0.0073, 0.6835, 0.6250, 0.3625, 0.0193, 0.0136,\n",
      "         0.2813, 0.0351]])\n",
      "ground truth  tensor([[0.4782, 0.5578, 0.6818, 0.6227, 0.1590, 0.6831, 0.7213, 0.6511, 0.6212,\n",
      "         0.4493, 0.6903, 0.2470, 0.2752, 0.6414, 0.3990, 0.4783, 0.6081, 0.8120,\n",
      "         0.5336, 0.4572, 0.5110, 0.7864, 0.9606, 0.2965, 0.4904, 0.6352, 0.2488,\n",
      "         0.7447, 0.5911, 0.5253, 0.6813, 0.6309, 0.5094, 0.5151, 0.7166, 0.5196,\n",
      "         1.0000, 0.2050, 0.8147, 0.2457, 0.3384, 0.6297, 0.8303, 0.2453, 0.8935,\n",
      "         0.7306, 0.5354, 0.4713, 0.3332, 0.2132, 0.3899, 0.5241, 0.7573, 0.7078,\n",
      "         0.6188, 0.4349, 0.3336, 0.8237, 0.5286, 0.4000, 0.6190, 0.5041, 0.4962,\n",
      "         0.8813, 0.4357, 0.7891, 0.5841, 0.6464, 0.3848, 0.7640, 0.4850, 0.4195,\n",
      "         0.5899, 0.3561, 0.2933, 0.4999, 0.0000, 0.4453, 0.3097, 0.5429, 0.8812,\n",
      "         0.6403, 0.5328, 0.6713, 0.4590, 0.7235, 0.4558, 0.5367, 0.6305, 0.5990,\n",
      "         0.3346, 0.4958, 0.5019, 0.7655, 0.7032, 0.2777, 0.4001, 0.3980, 0.2083,\n",
      "         0.5127, 0.4894, 0.5282, 0.4731, 0.2878, 0.3887, 0.7954, 0.4516, 0.2569,\n",
      "         0.8939, 0.6405, 0.4465, 0.6760, 0.8559, 0.4907, 0.5274, 0.4366, 0.5895,\n",
      "         0.8964, 0.5078, 0.3943, 0.5786, 0.6687, 0.8797, 0.3689, 0.3358, 0.7882,\n",
      "         0.3299, 0.3603, 0.4202, 0.4563, 0.5973, 0.5823, 0.1737, 0.8265, 0.4615,\n",
      "         0.8994, 0.4449, 0.2954, 0.9669, 0.4297, 0.6089, 0.9142, 0.4415, 0.7948,\n",
      "         0.4350, 0.4136, 0.6701, 0.8900, 0.2823, 0.4305, 0.5590, 0.3536, 0.6783,\n",
      "         0.7669, 0.3026, 0.6386, 0.3555, 0.5878, 0.3553, 0.5471, 0.5976, 0.5019,\n",
      "         0.3559, 0.8419, 0.8038, 0.7150, 0.4483, 0.3286, 0.4117, 0.5995, 0.5950,\n",
      "         0.6560, 0.3964, 0.6368, 0.5428, 0.7741, 0.9396, 0.5642, 0.4783, 0.3855,\n",
      "         0.4964, 0.6978, 0.5282, 0.2875, 0.6065, 0.5451, 0.4725, 0.6465, 0.5037,\n",
      "         0.7445, 0.5867, 0.5212, 0.4301, 0.9098, 0.4522, 0.3557, 0.7043, 0.5465,\n",
      "         0.5004, 0.6341]])\n",
      "loss arm tensor(0.6729)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/scipy/spatial/distance.py:728: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_test_losses  [1.3553053496443233]\n",
      "with normalization, threshold  0.8\n",
      "actual_zero_below_threshold  699\n",
      "found_zero_below_threshold  1563\n",
      "actual_one_below_threshold  864\n",
      "actual_one_above_threshold  9441\n",
      "found_one_above_threshold  17382\n",
      "actual_zero_above_threshold  7941\n"
     ]
    }
   ],
   "source": [
    "# PLEASE CHECK THIS CELL CAREFULLY\n",
    "# Run this cell\n",
    "# Testing for ROC curve with sent vector change\n",
    "# This is the main cell for preparing center words and cotext words and iterates over entire dataset\n",
    "# epochs = 10\n",
    "window_size = 2\n",
    "#TEST_CSV = 'test1.csv'\n",
    "#TEST_CSV = 'test_original.csv'\n",
    "TEST_CSV = 'test_all_original.csv'\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# 80% of total data in dataset is used for training and rest 20% will be used for testing\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# train_X, test_X = train_test_split (train_df, test_size=0.2 )\n",
    "\n",
    "questions_cols = ['lang1', 'lang2']\n",
    "dataset = test_df\n",
    "\n",
    "epoch_test_losses = list()\n",
    "\n",
    "unique_total_words = set()\n",
    "\n",
    "\n",
    "#keeping vocab size same as embedding dim\n",
    "# model_param = ModelParam(101, 101, 200, 200, 200)\n",
    "# model = crossLingualModel(model_param)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "threshold = 0.8\n",
    "actual_zero_below_threshold = 0\n",
    "found_zero_below_threshold = 0\n",
    "actual_one_below_threshold = 0\n",
    "actual_one_above_threshold = 0\n",
    "found_one_above_threshold = 0\n",
    "actual_zero_above_threshold = 0\n",
    "\n",
    "y_pred = list()\n",
    "y_true = list()\n",
    "\n",
    "if_to_print_output = 0\n",
    "\n",
    "# Testing\n",
    "with torch.no_grad():\n",
    "    \n",
    "    intermediate_test_losses = list()\n",
    "    for index, row in dataset.iterrows():\n",
    "        #if (index % 10) == 0:\n",
    "        #print('test dataset index', index)\n",
    "        #calculate paragraph vector for entire row\n",
    "        sent_vector = get_mean_vector(text_to_word_list(row))\n",
    "        #print(sent_vector)\n",
    "        \n",
    "        sent_vector_x86 = get_mean_vector(text_to_word_list(row['lang1']))\n",
    "        sent_vector_x86 = get_normalized_array_from_array_using_tensor_formula(sent_vector_x86)\n",
    "        sent_vector_arm = get_mean_vector(text_to_word_list(row['lang2']))\n",
    "        sent_vector_arm = get_normalized_array_from_array_using_tensor_formula(sent_vector_arm)\n",
    "        #print('sent_vector_x86 ',sent_vector_x86)\n",
    "        #print('sent_vector_arm ',sent_vector_arm)\n",
    "#         cos_sim = np.dot(sent_vector_x86, sent_vector_arm)/(np.linalg.norm(sent_vector_x86)*np.linalg.norm(sent_vector_arm))\n",
    "#         print('cos_sim ', cos_sim)\n",
    "        \n",
    "        result = 1 - spatial.distance.cosine(sent_vector_x86, sent_vector_arm)\n",
    "        # Calculates the distance as defined by the MaLSTM model\n",
    "#         result = merge(mode=lambda x: exponent_neg_manhattan_distance(x[0], x[1]), \\\n",
    "#                         output_shape=lambda x: (x[0][0], 1))([sent_vector_x86, sent_vector_arm])\n",
    "\n",
    "#         result = cityblock(sent_vector_x86, sent_vector_arm)\n",
    "        \n",
    "        \n",
    "        #print('if_similar ',row['if_similar'])\n",
    "        #print('result ',result)\n",
    "        #print('type = ',type(row['if_similar']))\n",
    "        if(result < threshold):\n",
    "            y_pred.append(0)\n",
    "            found_zero_below_threshold += 1\n",
    "            if(row['if_similar'] == 0):\n",
    "                actual_zero_below_threshold += 1\n",
    "            else:\n",
    "                actual_one_below_threshold += 1\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "            found_one_above_threshold += 1\n",
    "            if(row['if_similar'] == 1):\n",
    "                actual_one_above_threshold += 1\n",
    "            else:\n",
    "                actual_zero_above_threshold += 1\n",
    "        y_true.append(row['if_similar'])\n",
    "\n",
    "        #keeping vocab size same as embedding dim\n",
    "#             model_param = ModelParam(101, 101, 200, 200, 200, sent_vector)\n",
    "#             model = crossLingualModel(model_param)\n",
    "#             optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "            context_words_lang1_array = []\n",
    "            context_words_lang2_array = []\n",
    "            for word_lang1 in context_words_lang1:\n",
    "                unique_total_words.add(word_lang1)\n",
    "                #ADD CHECK For out of vocabulary word\n",
    "                lang1_array = np.array(get_word_embedding(word_lang1))\n",
    "\n",
    "                #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang1_array)\n",
    "#                     lang1_array = lang1_array/norm\n",
    "\n",
    "                context_words_lang1_array.append(lang1_array)\n",
    "\n",
    "            for word_lang2 in context_words_lang2:\n",
    "                unique_total_words.add(word_lang2)\n",
    "                #ADD CHECK For out of vocabulary word\n",
    "                lang2_array = np.array(get_word_embedding(word_lang2))\n",
    "\n",
    "                #For normalizing array\n",
    "#                     norm = np.linalg.norm(lang2_array)\n",
    "#                     lang2_array = lang2_array/norm\n",
    "\n",
    "                context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "            prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "\n",
    "\n",
    "\n",
    "            #embedding for target word in lang1\n",
    "            #ADD CHECK For out of vocabulary word\n",
    "            target1 = get_word_embedding(center_word_lang1)\n",
    "            \n",
    "            unique_total_words.add(center_word_lang1)\n",
    "            \n",
    "\n",
    "            # For normalizing\n",
    "#                 norm1 = np.linalg.norm(target1)\n",
    "#                 target1 = target1/norm1\n",
    "\n",
    "            target1 = torch.from_numpy(target1)\n",
    "            target1 = torch.autograd.Variable(target1)\n",
    "            target1 = target1.reshape(1,-1)\n",
    "\n",
    "            target1 = get_normalized_tensor(target1)\n",
    "\n",
    "            # Normalize prediction1\n",
    "#             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "#             #x = torch.randn(3, 224, 224)\n",
    "#             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "\n",
    "            prediction1 = get_normalized_tensor(prediction1)\n",
    "            #print(prediction1)\n",
    "\n",
    "#             if(epoch == 0):\n",
    "#                 print(prediction1)\n",
    "#                 print(prediction2)\n",
    "                #print(target1)\n",
    "                #print(np.sum(target1))\n",
    "\n",
    "            loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "            \n",
    "            if(if_to_print_output<2):\n",
    "                print('output ',prediction1)\n",
    "                print('ground truth ',target1)\n",
    "                print('loss x86', loss_lang1)\n",
    "            \n",
    "            #embedding for target word in lang2\n",
    "            #ADD CHECK For out of vocabulary word\n",
    "            target2 = get_word_embedding(center_word_lang2)\n",
    "            \n",
    "            unique_total_words.add(center_word_lang2)\n",
    "\n",
    "            # For normalizing\n",
    "#                 norm2 = np.linalg.norm(target2)\n",
    "#                 target2 = target2/norm2\n",
    "\n",
    "            target2 = torch.from_numpy(target2)\n",
    "            target2 = torch.autograd.Variable(target2)\n",
    "            target2 = target2.reshape(1,-1)\n",
    "\n",
    "            target2 = get_normalized_tensor(target2)\n",
    "\n",
    "\n",
    "            prediction2 = get_normalized_tensor(prediction2)\n",
    "\n",
    "            loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "            \n",
    "            if(if_to_print_output<2):\n",
    "                print('output ',prediction2)\n",
    "                print('ground truth ',target2)\n",
    "                print('loss arm', loss_lang1)\n",
    "                if_to_print_output += 1\n",
    "\n",
    "            summed_loss = loss_lang1 + loss_lang2  \n",
    "\n",
    "\n",
    "            intermediate_test_losses.append(summed_loss.item())\n",
    "\n",
    "            ## Assuming below lines not needed for test. need to confirm\n",
    "            #model.zero_grad()\n",
    "            #summed_loss.backward()\n",
    "            #optimizer.step()\n",
    "\n",
    "    #print('intermediate_test_losses')\n",
    "    #print(intermediate_test_losses)\n",
    "\n",
    "    epoch_test_losses.append(np.mean(intermediate_test_losses))\n",
    "    \n",
    "\n",
    "print('epoch_test_losses ',epoch_test_losses)\n",
    "#print('unique_total_words = ',len(unique_total_words))\n",
    "#print('unique_unknown_words = ',len(unique_unknown_words))\n",
    "\n",
    "# print('with manhattan_distance')\n",
    "print('with normalization, threshold ',threshold)\n",
    "print('actual_zero_below_threshold ',actual_zero_below_threshold)\n",
    "print('found_zero_below_threshold ',found_zero_below_threshold)\n",
    "print('actual_one_below_threshold ',actual_one_below_threshold)\n",
    "print('actual_one_above_threshold ',actual_one_above_threshold)\n",
    "print('found_one_above_threshold ',found_one_above_threshold)\n",
    "print('actual_zero_above_threshold ',actual_zero_above_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/home/user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages/ipykernel_launcher.py:85: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with normalization, threshold  -0.009\n",
      "actual_zero_below_threshold  30\n",
      "found_zero_below_threshold  46\n",
      "actual_one_below_threshold  16\n",
      "actual_one_above_threshold  33\n",
      "found_one_above_threshold  53\n",
      "actual_zero_above_threshold  20\n"
     ]
    }
   ],
   "source": [
    "# PLEASE CHECK THIS CELL CAREFULLY\n",
    "# Run this cell\n",
    "# Testing for ROC curve with sent vector change WITH UPDATED SENT CALCULATION\n",
    "\n",
    "window_size = 2\n",
    "#TEST_CSV = 'test1.csv'\n",
    "#TEST_CSV = 'test_original.csv'\n",
    "# TEST_CSV = 'test_all_original.csv'\n",
    "# TEST_CSV = 'test_all_original_short.csv'\n",
    "TEST_CSV = 'test_all_original_short_1.csv'\n",
    "\n",
    "\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "\n",
    "questions_cols = ['lang1', 'lang2']\n",
    "dataset = test_df\n",
    "\n",
    "epoch_test_losses = list()\n",
    "\n",
    "unique_total_words = set()\n",
    "\n",
    "\n",
    "# threshold = -.003\n",
    "threshold = -0.009\n",
    "\n",
    "actual_zero_below_threshold = 0\n",
    "found_zero_below_threshold = 0\n",
    "actual_one_below_threshold = 0\n",
    "actual_one_above_threshold = 0\n",
    "found_one_above_threshold = 0\n",
    "actual_zero_above_threshold = 0\n",
    "\n",
    "y_pred = list()\n",
    "y_true = list()\n",
    "\n",
    "if_to_print_output = 0\n",
    "\n",
    "# Testing\n",
    "with torch.no_grad():\n",
    "    \n",
    "    intermediate_test_losses = list()\n",
    "    for index, row in dataset.iterrows():\n",
    "        #if (index % 10) == 0:\n",
    "        #print('test dataset index', index)\n",
    "        #calculate paragraph vector for entire row\n",
    "        \n",
    "        sent_vector_x86 = row['lang1'] #get_mean_vector(text_to_word_list())\n",
    "        sent_vector_arm = row['lang2'] #get_mean_vector(text_to_word_list())\n",
    "        \n",
    "        prediction1, prediction2 = model(sent_vector_x86, sent_vector_arm, '')\n",
    "#         prediction1 = get_normalized_tensor(prediction1).detach().numpy()\n",
    "#         prediction2 = get_normalized_tensor(prediction2).detach().numpy()\n",
    "        \n",
    "        prediction1 = prediction1.detach().numpy()\n",
    "        prediction2 = prediction2.detach().numpy()\n",
    "        \n",
    "#         print('prediction1 for test ',prediction1)\n",
    "#         print('prediction2 for test ',prediction2)\n",
    "        \n",
    "        #print('sent_vector_x86 ',sent_vector_x86)\n",
    "        #print('sent_vector_arm ',sent_vector_arm)\n",
    "#         cos_sim = np.dot(sent_vector_x86, sent_vector_arm)/(np.linalg.norm(sent_vector_x86)*np.linalg.norm(sent_vector_arm))\n",
    "#         print('cos_sim ', cos_sim)\n",
    "        \n",
    "        result = 1 - spatial.distance.cosine(prediction1, prediction2)\n",
    "        # Calculates the distance as defined by the MaLSTM model\n",
    "#         result = merge(mode=lambda x: exponent_neg_manhattan_distance(x[0], x[1]), \\\n",
    "#                         output_shape=lambda x: (x[0][0], 1))([sent_vector_x86, sent_vector_arm])\n",
    "\n",
    "#         result = cityblock(sent_vector_x86, sent_vector_arm)\n",
    "        \n",
    "        \n",
    "        #print('if_similar ',row['if_similar'])\n",
    "        #print('result ',result)\n",
    "        #print('type = ',type(row['if_similar']))\n",
    "        if(result < threshold):\n",
    "            y_pred.append(0)\n",
    "            found_zero_below_threshold += 1\n",
    "            if(row['if_similar'] == 0):\n",
    "                actual_zero_below_threshold += 1\n",
    "            else:\n",
    "                actual_one_below_threshold += 1\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "            found_one_above_threshold += 1\n",
    "            if(row['if_similar'] == 1):\n",
    "                actual_one_above_threshold += 1\n",
    "            else:\n",
    "                actual_zero_above_threshold += 1\n",
    "        y_true.append(row['if_similar'])\n",
    "\n",
    "        #keeping vocab size same as embedding dim\n",
    "#             model_param = ModelParam(101, 101, 200, 200, 200, sent_vector)\n",
    "#             model = crossLingualModel(model_param)\n",
    "#             optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#         for context_words_lang1, context_words_lang2, center_word_lang1, center_word_lang2 in get_windows(text_to_word_list(row['lang1']), text_to_word_list(row['lang2']), window_size):\n",
    "#             context_words_lang1_array = []\n",
    "#             context_words_lang2_array = []\n",
    "#             for word_lang1 in context_words_lang1:\n",
    "#                 unique_total_words.add(word_lang1)\n",
    "#                 #ADD CHECK For out of vocabulary word\n",
    "#                 lang1_array = np.array(get_word_embedding(word_lang1))\n",
    "\n",
    "#                 #For normalizing array\n",
    "# #                     norm = np.linalg.norm(lang1_array)\n",
    "# #                     lang1_array = lang1_array/norm\n",
    "\n",
    "#                 context_words_lang1_array.append(lang1_array)\n",
    "\n",
    "#             for word_lang2 in context_words_lang2:\n",
    "#                 unique_total_words.add(word_lang2)\n",
    "#                 #ADD CHECK For out of vocabulary word\n",
    "#                 lang2_array = np.array(get_word_embedding(word_lang2))\n",
    "\n",
    "#                 #For normalizing array\n",
    "# #                     norm = np.linalg.norm(lang2_array)\n",
    "# #                     lang2_array = lang2_array/norm\n",
    "\n",
    "#                 context_words_lang2_array.append(lang2_array)\n",
    "\n",
    "#             prediction1, prediction2 = model(np.array(context_words_lang1_array), np.array(context_words_lang2_array), sent_vector)\n",
    "\n",
    "\n",
    "\n",
    "#             #embedding for target word in lang1\n",
    "#             #ADD CHECK For out of vocabulary word\n",
    "#             target1 = get_word_embedding(center_word_lang1)\n",
    "            \n",
    "#             unique_total_words.add(center_word_lang1)\n",
    "            \n",
    "\n",
    "#             # For normalizing\n",
    "# #                 norm1 = np.linalg.norm(target1)\n",
    "# #                 target1 = target1/norm1\n",
    "\n",
    "#             target1 = torch.from_numpy(target1)\n",
    "#             target1 = torch.autograd.Variable(target1)\n",
    "#             target1 = target1.reshape(1,-1)\n",
    "\n",
    "#             target1 = get_normalized_tensor(target1)\n",
    "\n",
    "#             # Normalize prediction1\n",
    "# #             normPrediction1 = transforms.Normalize(prediction1, prediction1)\n",
    "# #             #x = torch.randn(3, 224, 224)\n",
    "# #             prediction1 = normPrediction1(prediction1)\n",
    "\n",
    "\n",
    "#             prediction1 = get_normalized_tensor(prediction1)\n",
    "#             #print(prediction1)\n",
    "\n",
    "# #             if(epoch == 0):\n",
    "# #                 print(prediction1)\n",
    "# #                 print(prediction2)\n",
    "#                 #print(target1)\n",
    "#                 #print(np.sum(target1))\n",
    "\n",
    "#             loss_lang1 = nn.BCEWithLogitsLoss()(prediction1, target1)\n",
    "            \n",
    "#             if(if_to_print_output<2):\n",
    "#                 print('output ',prediction1)\n",
    "#                 print('ground truth ',target1)\n",
    "#                 print('loss x86', loss_lang1)\n",
    "            \n",
    "#             #embedding for target word in lang2\n",
    "#             #ADD CHECK For out of vocabulary word\n",
    "#             target2 = get_word_embedding(center_word_lang2)\n",
    "            \n",
    "#             unique_total_words.add(center_word_lang2)\n",
    "\n",
    "#             # For normalizing\n",
    "# #                 norm2 = np.linalg.norm(target2)\n",
    "# #                 target2 = target2/norm2\n",
    "\n",
    "#             target2 = torch.from_numpy(target2)\n",
    "#             target2 = torch.autograd.Variable(target2)\n",
    "#             target2 = target2.reshape(1,-1)\n",
    "\n",
    "#             target2 = get_normalized_tensor(target2)\n",
    "\n",
    "\n",
    "#             prediction2 = get_normalized_tensor(prediction2)\n",
    "\n",
    "#             loss_lang2 = nn.BCEWithLogitsLoss()(prediction2, target2)\n",
    "            \n",
    "#             if(if_to_print_output<2):\n",
    "#                 print('output ',prediction2)\n",
    "#                 print('ground truth ',target2)\n",
    "#                 print('loss arm', loss_lang1)\n",
    "#                 if_to_print_output += 1\n",
    "\n",
    "#             summed_loss = loss_lang1 + loss_lang2  \n",
    "\n",
    "\n",
    "#             intermediate_test_losses.append(summed_loss.item())\n",
    "\n",
    "#             ## Assuming below lines not needed for test. need to confirm\n",
    "#             #model.zero_grad()\n",
    "#             #summed_loss.backward()\n",
    "#             #optimizer.step()\n",
    "\n",
    "#     #print('intermediate_test_losses')\n",
    "#     #print(intermediate_test_losses)\n",
    "\n",
    "#     epoch_test_losses.append(np.mean(intermediate_test_losses))\n",
    "    \n",
    "\n",
    "# print('epoch_test_losses ',epoch_test_losses)\n",
    "#print('unique_total_words = ',len(unique_total_words))\n",
    "#print('unique_unknown_words = ',len(unique_unknown_words))\n",
    "\n",
    "# print('with manhattan_distance')\n",
    "print('with normalization, threshold ',threshold)\n",
    "print('actual_zero_below_threshold ',actual_zero_below_threshold)\n",
    "print('found_zero_below_threshold ',found_zero_below_threshold)\n",
    "print('actual_one_below_threshold ',actual_one_below_threshold)\n",
    "print('actual_one_above_threshold ',actual_one_above_threshold)\n",
    "print('found_one_above_threshold ',found_one_above_threshold)\n",
    "print('actual_zero_above_threshold ',actual_zero_above_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)*100\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', linewidth = 1.2, label='Crosslingual Model (AUC = %0.2f%%)' % roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color = 'silver', linestyle = ':', linewidth = 1.2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
